---
title : "Thi·∫øt l·∫≠p IDP Pipeline"
date :  "`r Sys.Date()`" 
weight : 8
chapter : false
pre : " <b> 5.8 </b> "
---

Trong ph·∫ßn n√†y, b·∫°n s·∫Ω setup SQS Worker ƒë·ªÉ x·ª≠ l√Ω documents qua IDP (Intelligent Document Processing) pipeline.

---

## IDP Flow

```
Upload ‚Üí S3 ‚Üí DynamoDB (UPLOADED) ‚Üí SQS
                                     ‚Üì
                              EC2 Worker
                                     ‚Üì
                    PyPDF2 (digital) / Textract (scanned)
                                     ‚Üì
                         Chunk Text (1000 tokens)
                                     ‚Üì
                    Cohere Embed Multilingual v3 (Bedrock)
                                     ‚Üì
                         Qdrant (store vectors)
                                     ‚Üì
                      DynamoDB (EMBEDDING_DONE)
```

> üí° **Note**: Worker s·ª≠ d·ª•ng **PyPDF2** cho PDF digital (text-based) v√† **Textract** cho PDF scanned (image-based).

---

## Document States

| Status | Description |
|--------|-------------|
| `UPLOADED` | File ƒë√£ upload, ƒëang ch·ªù x·ª≠ l√Ω |
| `IDP_RUNNING` | Worker ƒëang x·ª≠ l√Ω |
| `TEXTRACT_DONE` | OCR ho√†n t·∫•t (ch·ªâ cho scanned PDF) |
| `EMBEDDING_DONE` | Ho√†n t·∫•t, s·∫µn s√†ng s·ª≠ d·ª•ng |
| `FAILED` | C√≥ l·ªói x·∫£y ra |

---

## B∆∞·ªõc 1: Truy c·∫≠p EC2 qua Session Manager

```bash
# L·∫•y Instance ID
INSTANCE_ID=$(terraform -chdir=terraform output -raw ec2_instance_id)

# K·∫øt n·ªëi
aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1
```

Sau khi k·∫øt n·ªëi:
```bash
sudo su - ec2-user
cd /home/ec2-user/backend
```

> üí° **Note**: Tr√™n EC2 c√≥ 2 folders:
> - `app/` - Boilerplate t·ª´ user_data script
> - `backend/` - Code th·ª±c t·∫ø ƒë∆∞·ª£c deploy qua CI/CD (ch·ª©a run_worker.py)

---

## B∆∞·ªõc 2: Ki·ªÉm tra Worker Code

Worker code n·∫±m trong `backend/run_worker.py`. Ki·ªÉm tra file ƒë√£ c√≥:

```bash
ls -la
# Ph·∫£i c√≥: run_worker.py, app/, requirements.txt
```

![Worker Files](/images/5-Workshop/8-idp-pipeline/worker-files.png)

---

## B∆∞·ªõc 3: C·∫•u h√¨nh Environment

ƒê·∫£m b·∫£o file `.env` c√≥ ƒë·∫ßy ƒë·ªß c√°c bi·∫øn (trong folder `backend/`):

```bash
cd /home/ec2-user/backend
cat .env
```

C√°c bi·∫øn quan tr·ªçng cho IDP:
```
SQS_QUEUE_URL=https://sqs.ap-southeast-1.amazonaws.com/<account>/arc-dev-document-queue
S3_BUCKET=arc-documents-<account>
QDRANT_HOST=localhost
QDRANT_PORT=6333
AWS_REGION=ap-southeast-1
```

---

## B∆∞·ªõc 4: Start Worker

### Option A: Ch·∫°y tr·ª±c ti·∫øp (ƒë·ªÉ debug)

```bash
# Activate virtual environment (n·∫øu c√≥)
source venv/bin/activate

# Ch·∫°y worker
python run_worker.py
```

Worker s·∫Ω hi·ªÉn th·ªã:
```
============================================================
IDP Pipeline - SQS Worker
============================================================
Queue URL: https://sqs.ap-southeast-1.amazonaws.com/xxx/arc-dev-document-queue
Bucket: arc-documents-xxx
Region: ap-southeast-1
Qdrant: localhost:6333
------------------------------------------------------------
Processing indefinitely (Ctrl+C to stop)...
```

### Option B: Ch·∫°y trong background v·ªõi nohup

```bash
nohup python run_worker.py > worker.log 2>&1 &

# Ki·ªÉm tra process
ps aux | grep run_worker

# Xem logs
tail -f worker.log
```

### Option C: Ch·∫°y trong Docker (recommended)

```bash
# Th√™m worker v√†o docker-compose.yml
docker-compose up -d worker
```

---

## B∆∞·ªõc 5: Test IDP Pipeline

### 5.1 Upload test file l√™n S3

```bash
# T·ª´ m√°y local
aws s3 cp test-sample.pdf s3://arc-documents-<account>/uploads/test-001.pdf
```

### 5.2 T·∫°o record trong DynamoDB

```bash
aws dynamodb put-item \
  --table-name arc-dev-documents \
  --item '{
    "doc_id": {"S": "test-001"},
    "sk": {"S": "METADATA"},
    "filename": {"S": "test-sample.pdf"},
    "s3_key": {"S": "uploads/test-001.pdf"},
    "status": {"S": "UPLOADED"},
    "uploaded_at": {"S": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}
  }'
```

### 5.3 G·ª≠i message v√†o SQS

```bash
aws sqs send-message \
  --queue-url https://sqs.ap-southeast-1.amazonaws.com/<account>/arc-dev-document-queue \
  --message-body '{
    "doc_id": "test-001",
    "s3_key": "uploads/test-001.pdf",
    "filename": "test-sample.pdf"
  }'
```

---

## B∆∞·ªõc 6: Monitor Processing

Xem logs c·ªßa worker:

```bash
# N·∫øu ch·∫°y tr·ª±c ti·∫øp
# Logs hi·ªÉn th·ªã tr√™n terminal

# N·∫øu ch·∫°y background
tail -f worker.log
```

Logs th√†nh c√¥ng s·∫Ω nh∆∞ sau:
```
2024-01-15 10:30:00 - INFO - Received message for doc_id: test-001
2024-01-15 10:30:01 - INFO - Downloading from S3: uploads/test-001.pdf
2024-01-15 10:30:02 - INFO - Extracting text with PyPDF2...
2024-01-15 10:30:03 - INFO - Created 8 chunks from document
2024-01-15 10:30:05 - INFO - Generating embeddings with Cohere...
2024-01-15 10:30:10 - INFO - Stored 8 vectors for test-001
2024-01-15 10:30:10 - INFO - Updated status: EMBEDDING_DONE
2024-01-15 10:30:10 - INFO - Document test-001 processed successfully
```

---

## B∆∞·ªõc 7: Verify Processing

### 7.1 Ki·ªÉm tra DynamoDB

```bash
aws dynamodb get-item \
  --table-name arc-dev-documents \
  --key '{"doc_id":{"S":"test-001"},"sk":{"S":"METADATA"}}' \
  --query 'Item.{status:status.S,chunks:chunk_count.N}'
```

Expected output:
```json
{
  "status": "EMBEDDING_DONE",
  "chunks": "8"
}
```

### 7.2 Ki·ªÉm tra Qdrant

```bash
# Tr√™n EC2
curl -s http://localhost:6333/collections/arc_documents/points/count | jq
```

Expected output:
```json
{
  "result": {
    "count": 8
  }
}
```
---

## X·ª≠ l√Ω L·ªói

| V·∫•n ƒë·ªÅ | Nguy√™n nh√¢n | Gi·∫£i ph√°p |
|--------|-------------|-----------|
| Worker kh√¥ng nh·∫≠n message | SQS URL sai | Ki·ªÉm tra `.env` |
| Bedrock timeout | Rate limit | TƒÉng retry delay |
| Qdrant connection refused | Container ch∆∞a start | `docker-compose up -d qdrant` |
| FAILED status | Xem error_message trong DynamoDB | Fix v√† retry |

### Retry Failed Document

```bash
# C·∫≠p nh·∫≠t status v·ªÅ UPLOADED ƒë·ªÉ retry
aws dynamodb update-item \
  --table-name arc-dev-documents \
  --key '{"doc_id":{"S":"test-001"},"sk":{"S":"METADATA"}}' \
  --update-expression "SET #s = :s" \
  --expression-attribute-names '{"#s":"status"}' \
  --expression-attribute-values '{":s":{"S":"UPLOADED"}}'

# G·ª≠i l·∫°i message v√†o SQS
aws sqs send-message \
  --queue-url $SQS_QUEUE_URL \
  --message-body '{"doc_id":"test-001","s3_key":"uploads/test-001.pdf","filename":"test-sample.pdf"}'
```

---

## Checklist

- [ ] Truy c·∫≠p EC2 qua Session Manager
- [ ] Worker code c√≥ s·∫µn
- [ ] Environment variables configured
- [ ] Worker ƒëang ch·∫°y
- [ ] Test document uploaded to S3
- [ ] SQS message sent
- [ ] Worker processed document (logs)
- [ ] Status = EMBEDDING_DONE trong DynamoDB
- [ ] Vectors stored trong Qdrant
