[{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Tuấn Kha\nSố điện thoại: 0835173787\nEmail: khantse183212@fpt.edu.vn\nTrường: Đại học FPT cơ sở Hồ Chí Minh\nNgành: Kĩ thuật phần mềm\nLớp: AWS092025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 06/09/2025 đến ngày 9/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Tuần 1: Làm quen với AWS và các dịch vụ cơ bản (Cloud Fundamentals, IAM, Budget, Support).\nTuần 2: Học VPC cơ bản và các kiến thức networking nền tảng.\nTuần 3: Nâng cao EC2 trong VPC, NAT Gateway, Security Group, DNS Resolver.\nTuần 4: VPC Peering, Transit Gateway và kết nối phức tạp giữa VPC.\nTuần 5: Compute Services: EC2, Auto Scaling, Backup và Storage Gateway.\nTuần 6: Storage nâng cao: S3, Glacier, FSx và Storage Gateway.\nTuần 7: IAM nâng cao, AWS Organizations, Identity Center, KMS.\nTuần 8: Database Services, ETL (Kinesis/Glue/Athena), DMS Migration.\nTuần 9: Workshop – Thiết kế kiến trúc hệ thống trên AWS (Architecture Design).\nTuần 10: Workshop – Xây dựng Database + Backend + Frontend.\nTuần 11: Workshop – Hoàn thiện FE + Deploy toàn bộ hệ thống.\nTuần 12: Workshop – Kiểm tra, test, tối ưu \u0026amp; viết báo cáo tổng hợp.\n"},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu Tuần 1: Hiểu cấu trúc tài khoản AWS và vai trò của Root User. Học cách tạo và bảo mật tài khoản AWS. Thiết lập IAM User, IAM Group và gán chính sách quyền. Kích hoạt MFA và cấu hình cảnh báo chi phí. Làm quen với giao diện AWS Management Console. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Tổng quan về tài khoản AWS và trách nhiệm của Root User - Hiểu các khái niệm IAM (User, Group, Policy) 09/09/2025 09/09/2025 https://000001.awsstudygroup.com/ 2 - Tạo tài khoản AWS - Thêm phương thức thanh toán - Xác thực email \u0026amp; số điện thoại - Đăng nhập lần đầu và khám phá AWS Console 09/10/2025 09/10/2025 https://000001.awsstudygroup.com/ 3 - Bảo mật tài khoản Root + Kích hoạt MFA + Cấu hình password policy + Giảm thiểu việc sử dụng Root User - Thiết lập Billing Preferences \u0026amp; theo dõi Free Tier 09/11/2025 09/11/2025 https://000001.awsstudygroup.com/ 4 - Tạo IAM Group (Administrators) - Gắn AdministratorAccess policy - Tạo IAM User - Cấu hình đăng nhập cho user và bật MFA 09/12/2025 09/12/2025 https://000001.awsstudygroup.com/ 5 - Tạo Budget và Billing Alerts - Kiểm tra danh sách bảo mật tài khoản - Thực hành đăng nhập bằng IAM User - Khám phá giao diện AWS Console - Tổng kết bài học \u0026amp; các vấn đề phát sinh 09/13/2025 09/13/2025 https://000001.awsstudygroup.com/ Thành tựu Tuần 1: Hiểu rõ các thành phần của tài khoản AWS:\nRoot User IAM Users IAM Groups Policies Tạo và kích hoạt thành công tài khoản AWS mới.\nBảo mật tài khoản Root bằng MFA và thiết lập tiêu chuẩn mật khẩu.\nThiết lập Billing Preferences, theo dõi Free Tier và cấu hình ngân sách cảnh báo chi phí.\nTạo IAM Group và IAM User theo đúng best practices của AWS.\nKích hoạt MFA cho IAM User và thực hành quy trình đăng nhập bảo mật.\nLàm quen với AWS Management Console và cách tìm kiếm dịch vụ nhanh chóng.\nHoàn thành các bước bảo mật nền tảng trước khi bắt đầu sử dụng các dịch vụ AWS trong các tuần tiếp theo.\n"},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/5-workshop/5.1-introduction/","title":"Giới thiệu","tags":[],"description":"","content":"Tuyên bố vấn đề Các hệ thống chatbot truyền thống gặp khó khăn khi không có khả năng truy cập thông tin cụ thể từ tài liệu nội bộ, dẫn đến trả lời không chính xác hoặc không liên quan. Workshop này giải quyết vấn đề bằng cách xây dựng một kiến trúc có khả năng:\nTự động hóa: Xử lý và đánh chỉ mục tài liệu PDF tự động Hỏi nội dung: Nhận truy vấn và điều hướng người dùng đến nội dung liên quan Truy xuất tài liệu: Trả lời các câu hỏi phức tạp với trích dẫn nguồn chính xác từ tài liệu Kiến trúc giải pháp Hệ thống được thiết kế theo mô hình RAG (Retrieval-Augmented Generation) kết hợp với AWS Serverless để đảm bảo khả năng mở rộng:\nFrontend Interface: Người dùng tương tác qua React Web Application\nAmazon API Gateway nhận requests từ Frontend AWS Amplify hosting với CloudFront CDN Amazon Cognito xử lý authentication Request Handling:\nApplication Load Balancer định tuyến traffic đến EC2 FastAPI Backend xử lý REST API requests Amazon SQS (FIFO) đảm bảo thứ tự xử lý documents Backend Processing:\nChatHandler: Quản lý hội thoại, lưu session vào Amazon DynamoDB RAG Service: Orchestrate vector search và LLM generation Qdrant Vector Database: Self-hosted trên EC2 cho vector search AI \u0026amp; Data Layer:\nAmazon Bedrock: Sử dụng Claude 3.5 Sonnet (LLM) và Cohere Embed Multilingual v3 (Embeddings) Amazon Textract: OCR và trích xuất text từ PDF Amazon S3: Lưu trữ documents Amazon DynamoDB: Metadata và chat history Admin Dashboard:\nReact-based interface hosted trên AWS Amplify Upload và quản lý documents Monitor processing status View chat history Architect Key Technologies Trong workshop này, bạn sẽ làm việc với các dịch vụ AWS chính sau:\nAmazon Bedrock: Trái tim của AI, cung cấp các Foundation Models (Claude, Cohere) để xử lý ngôn ngữ và sinh embeddings Amazon Textract: Xây dựng IDP pipeline để trích xuất text từ PDF documents Amazon EC2 \u0026amp; VPC: Cơ sở hạ tầng compute và network cho backend services Amazon S3: Lưu trữ documents và static assets Amazon DynamoDB: Lưu trữ metadata, chat history và document status Amazon Cognito: Authentication và user management AWS Amplify: Hosting frontend application với CI/CD tích hợp Amazon SQS: Message queue cho document processing pipeline Qdrant (Self-hosted): Vector database cho semantic search Terraform (IaC): Triển khai toàn bộ hạ tầng dưới dạng mã "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Academic Research Chatbot Giải pháp AWS RAG-based hỗ trợ học thuật và nghiên cứu học tập thông minh 1. Tóm tắt điều hành Academic Research Chatbot là trợ lý AI hỗ trợ nghiên cứu học thuật, giúp sinh viên và giảng viên tra cứu, tóm tắt và phân tích tài liệu khoa học (PDF, bài báo) thông qua hội thoại tự nhiên có trích dẫn nguồn chính xác.\nĐiểm nổi bật của giải pháp:\nCông nghệ lõi: Kết hợp IDP (Amazon Textract) để xử lý tài liệu (kể cả bản scan) và RAG (Amazon Bedrock - Claude 3.5 Sonnet) để sinh câu trả lời thông minh. Kiến trúc tối ưu: Mô hình Hybrid sử dụng 1 EC2 t3.small kết hợp các dịch vụ Serverless (Amplify, Cognito, S3, DynamoDB) để cân bằng hiệu năng và chi phí. Tính khả thi: Phục vụ ~50 người dùng nội bộ với chi phí vận hành ~60 USD/tháng, thời gian triển khai nhanh (20 ngày) và tận dụng tối đa AWS Free Tier. 2. Tuyên bố vấn đề Vấn đề hiện tại Sinh viên và researcher phải làm việc với số lượng lớn tài liệu học thuật (paper hội nghị, journal, luận văn, báo cáo kỹ thuật). Nhiều tài liệu là scan PDF cũ (trước năm 2000), không có text layer, khiến việc tìm kiếm nội dung, số liệu, bảng biểu rất tốn thời gian. Các công cụ AI công cộng (ChatGPT, Perplexity, NotebookLM, v.v.) không được kết nối trực tiếp với kho tài liệu nội bộ của trường/khoa, khó đảm bảo bảo mật và quyền truy cập theo môn học hoặc nhóm nghiên cứu. Hạ tầng hiện tại không có một điểm truy cập thống nhất để:\nQuản lý tài liệu nghiên cứu theo bộ môn/đề tài. Cho phép researcher đặt câu hỏi trực tiếp trên chính các paper của mình. Đảm bảo câu trả lời có trích dẫn rõ ràng (paper, trang, bảng, mục). Hệ quả: nghiên cứu viên phải đọc thủ công, note tay, copy số liệu từ nhiều paper; giảng viên khó tổng hợp nhanh thông tin khi chuẩn bị bài giảng hoặc đề tài; dữ liệu học thuật phân tán trên nhiều máy cá nhân, khó chuẩn hóa và tái sử dụng. Giải pháp Academic Research Chatbot đề xuất xây dựng một nền tảng hỏi – đáp học thuật nội bộ dựa trên AWS, nơi:\nDev/Admin nạp kho tài liệu nghiên cứu: Upload PDF vào Amazon S3, metadata được lưu trong Amazon DynamoDB. Một EC2 worker tiêu thụ hàng đợi Amazon SQS, gọi Amazon Textract để OCR, trích xuất text, bảng, biểu mẫu, kể cả tài liệu scan. Worker chuẩn hóa/chunk nội dung, gửi sang Amazon Bedrock Titan Text Embeddings v2 để sinh embedding, và index vào Qdrant trên EC2. Researchers đặt câu hỏi qua giao diện web (Amplify + CloudFront): Câu hỏi được embed, truy vấn Qdrant để lấy các đoạn liên quan nhất (Retrieval). Các đoạn này được chuyển vào Claude 3.5 Sonnet trên Amazon Bedrock để sinh câu trả lời có citation chính xác (paper, page, section, table) và giải thích theo ngữ cảnh học thuật. Toàn bộ truy cập được bảo vệ bởi Amazon Cognito (phân quyền researcher vs admin), log \u0026amp; metric được giám sát qua Amazon CloudWatch + SNS (cảnh báo khi có lỗi worker, queue backlog, CPU EC2 cao). Lợi ích và hoàn vốn đầu tư (ROI) Hiệu quả học thuật:\nGiảm 40–60% thời gian researcher phải bỏ ra để tìm số liệu, F1-score, p-value, sample size, thiết bị thí nghiệm hoặc mô tả phương pháp từ nhiều paper khác nhau. Giảm sai sót khi trích dẫn do quên trang/bảng, vì chatbot luôn trả kèm nguồn và vị trí. Quản lý tri thức nội bộ: Tài liệu nghiên cứu được tập trung về một kho S3 + DynamoDB, dễ backup, phân quyền, và mở rộng. Có thể tái sử dụng cho nhiều khoá học, đề tài và lab khác nhau mà không phải xây hệ thống mới. Chi phí hạ tầng thấp \u0026amp; dễ kiểm soát: Mô hình hybrid 1 EC2 + managed AI services giúp chi phí vận hành cho 50 users nội bộ giữ ở mức khoảng \u0026lt; 50 USD/tháng, chủ yếu trả cho EC2, 2–3 VPC endpoint interface và phần sử dụng Bedrock/Textract. Hệ thống được thiết kế để triển khai trong khoảng 20 ngày bởi team 4 người, phù hợp làm dự án nghiên cứu/thực tập nhưng vẫn có chất lượng kiến trúc sản phẩm. Giá trị dài hạn: Tạo nền tảng để sau này tích hợp thêm dashboard phân tích hành vi học tập, module recommend paper, hoặc mở rộng sang trợ lý học tập đa ngôn ngữ và đa lĩnh vực. 3. Kiến trúc giải pháp Academic Research Chatbot áp dụng mô hình AWS Hybrid RAG Architecture với IDP (Intelligent Document Processing), kết hợp một EC2 duy nhất (FastAPI + Qdrant + Worker) với các dịch vụ AI managed (Textract, Bedrock) để vừa tối ưu chi phí, vừa đảm bảo hiệu năng cho khoảng 50 người dùng nội bộ.\nLuồng xử lý dữ liệu và hội thoại\nDịch vụ AWS sử dụng\nFrontend: Route 53, CloudFront, Amplify (DNS, CDN, Host React App). Auth: Cognito (Xác thực \u0026amp; phân quyền researcher/admin). Compute: EC2 t3.small (FastAPI + Qdrant + Worker). AI/ML: Bedrock (Claude 3.5 Sonnet, Titan Embeddings v2). IDP: Textract (OCR cho PDF scan). Storage: S3, DynamoDB (File PDF gốc + Metadata/Status). Queue: SQS (Hàng đợi xử lý tài liệu). Network: VPC, ALB, VPC Endpoints (Bảo mật, routing, kết nối AWS Services). Monitoring: CloudWatch, SNS (Logs, Metrics, Alerts). CI/CD: CodePipeline, CodeBuild (Auto deploy backend). Thiết kế thành phần\nNgười dùng: Researchers: hỏi – đáp, tra cứu nội dung học thuật. Dev/Admin: upload, quản lý và re-index tài liệu. Xử lý tài liệu (IDP): PDF được Dev/Admin upload lên S3. Worker trên EC2 gọi Textract để OCR và trích xuất text/bảng. Lập chỉ mục (Indexing \u0026amp; Vector DB): Worker chuẩn hoá, chia chunk nội dung. Gọi Bedrock Titan Embeddings v2 tạo embedding. Lưu embedding + metadata vào Qdrant trên EC2. Hội thoại AI (RAG): FastAPI embed câu hỏi, truy vấn Qdrant lấy top-k đoạn liên quan. Gửi context + câu hỏi vào Claude 3.5 Sonnet (Bedrock) để sinh câu trả lời kèm citation. Quản lý người dùng: Cognito xác thực và phân quyền researcher / admin. Lưu trữ \u0026amp; trạng thái: DynamoDB lưu metadata tài liệu (doc_id, status, owner, …) và (tuỳ chọn) lịch sử chat. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm 2 phần chính — nền tảng web (UI + auth) và backend RAG + IDP — triển khai qua 4 giai đoạn:\nNghiên cứu \u0026amp; chốt kiến trúc: Rà soát yêu cầu (50 researcher, 1 EC2, IDP + RAG). Chốt kiến trúc VPC, EC2 (FastAPI + Qdrant + Worker), Amplify, Cognito, S3, SQS, DynamoDB, Textract, Bedrock. POC \u0026amp; kiểm tra kết nối: Tạo EC2, VPC endpoints, thử gọi Textract, Titan Embeddings, Claude 3.5 Sonnet. Chạy Qdrant đơn giản trên EC2, test insert/search vector. Tạo skeleton FastAPI + một màn hình Chat UI tối giản trên Amplify. Hoàn thiện tính năng chính: Xây /api/chat (FastAPI) + RAG pipeline: embed query → Qdrant → Claude + citation. Xây /api/admin/: upload PDF, lưu S3 + DynamoDB, đưa message vào SQS. Viết Worker trên EC2: SQS → Textract → normalize/chunk → Titan → Qdrant → update DynamoDB. Hoàn thiện Chat UI và Admin UI (upload + xem trạng thái tài liệu). Kiểm thử, tối ưu, triển khai demo nội bộ: Test end-to-end với một tập ~50–100 paper. Thêm CloudWatch Logs/Alarms, SNS notify khi lỗi hoặc queue backlog. Điều chỉnh cấu hình EC2, Qdrant, batch size để tối ưu thời gian và chi phí. Chuẩn bị tài liệu hướng dẫn sử dụng và demo cho nhóm 50 researcher. Yêu cầu kỹ thuật Frontend \u0026amp; Auth: React/Next.js host trên AWS Amplify, CDN CloudFront, DNS Route 53. Amazon Cognito quản lý định danh và phân quyền (Researcher/Admin). Backend \u0026amp; Compute: EC2 t3.small (Private Subnet) chạy All-in-one: FastAPI, Qdrant Vector DB và Worker. Xử lý bất đồng bộ: Worker đọc SQS, kích hoạt Textract và Bedrock để index dữ liệu. IDP \u0026amp; RAG: Lưu trữ: S3 (File gốc), DynamoDB (Metadata \u0026amp; Trạng thái). AI Core: Textract (OCR tài liệu scan), Bedrock Titan (Embedding), Claude 3.5 Sonnet (Trả lời câu hỏi). Mạng \u0026amp; Observability: Network: VPC Private Subnet, VPC Endpoints để kết nối bảo mật tới AWS Services. Monitoring: CloudWatch Logs/Metrics + SNS cảnh báo sự cố (CPU cao, lỗi Worker). 5. Lộ trình \u0026amp; Mốc triển khai Dự án được thực hiện trong khoảng 6 tuần với các giai đoạn cụ thể:\nTuần 1-2 (Ngày 1-10): Nghiên cứu \u0026amp; Thiết kế Thiết kế kiến trúc chi tiết, xác định scope, dịch vụ sử dụng. Lên kế hoạch tối ưu chi phí vận hành và triển khai. Tuần 3 (Ngày 11-15): Thiết lập hạ tầng AWS Cấu hình VPC, Subnets, Security Groups, IAM Roles. Triển khai EC2 t3.small, S3 bucket, DynamoDB tables. Thiết lập VPC Endpoints (Gateway + Interface). Tuần 4 (Ngày 16-20): Backend APIs \u0026amp; IDP Pipeline Xây dựng FastAPI endpoints (/api/chat, /api/admin/upload). Tích hợp IDP pipeline: SQS → Worker → Textract → Embeddings → Qdrant. Kết nối Bedrock (Titan Embeddings + Claude 3.5 Sonnet). Tuần 5 (Ngày 21-25): Testing \u0026amp; Error Handling Kiểm thử end-to-end với tập ~50-100 papers. Xử lý edge cases, retry logic, error handling. Tối ưu chunking strategy và retrieval accuracy. Tuần 6 (Ngày 26-30): Deployment \u0026amp; Documentation Hoàn thiện UI/UX cho Admin và Researcher. Thiết lập CloudWatch Alarms + SNS notifications. Chuẩn bị tài liệu hướng dẫn và demo cho nhóm 50 researcher. 6. Ước tính ngân sách Chi phí hạ tầng (ước tính theo tháng)\nCompute \u0026amp; Storage: EC2 t3.small: $10.08 (720h). EBS gp3: $2.40 (30GB). Network: NAT Gateway: $21.60. VPC Interface Endpoints: $14.60 (2 endpoints cho Textract, Bedrock). VPC Gateway Endpoints: FREE (S3, DynamoDB). AI \u0026amp; Operations: Bedrock Claude 3.5 Sonnet: $25.00 (50 users). Bedrock Titan Embeddings: $0.75 (750 papers). CloudWatch + Data Transfer: $1.90. Free Tier (12 tháng đầu)\nWeb \u0026amp; Auth: S3, CloudFront, Cognito, Amplify (FREE). Serverless: DynamoDB, SQS, SNS (Always FREE). IDP: Textract AnalyzeDocument (100 pages/month trong 3 tháng đầu). Tổng cộng: ~$60-76/tháng (tùy mức sử dụng Bedrock).\n7. Đánh giá rủi ro Ma trận rủi ro\nHallucination (AI bịa đặt): Ảnh hưởng cao, xác suất trung bình. Vượt ngân sách (AI Services): Ảnh hưởng trung bình, xác suất trung bình. Sự cố hạ tầng (EC2/Qdrant): Ảnh hưởng cao, xác suất thấp. Chiến lược giảm thiểu\nChất lượng AI: Bắt buộc trích dẫn nguồn (citation), giới hạn context đầu vào từ Qdrant. Chi phí: Thiết lập AWS Budgets/Alarms, kiểm soát số lượng tài liệu ingest. Hạ tầng \u0026amp; Bảo mật: Backup EBS định kỳ, mã hóa dữ liệu (S3/DynamoDB), phân quyền chặt chẽ qua Cognito/IAM. Kế hoạch dự phòng\nSự cố hệ thống: Khôi phục từ Snapshot, tạm dừng ingestion (buffer qua SQS). Vượt chi phí: Tạm khóa tính năng upload mới, giới hạn hạn ngạch truy vấn trong ngày. 8. Kết quả kỳ vọng Cải tiến kỹ thuật\nChuyển đổi kho tài liệu rời rạc (PDF/Scan) thành tri thức số có thể truy vấn và trích dẫn tự động. Giảm đáng kể thời gian tra cứu thủ công nhờ công nghệ RAG + IDP. Giá trị dài hạn Xây dựng nền tảng nghiên cứu số hóa cho 50+ researcher, dễ dàng mở rộng quy mô. Tạo tiền đề phát triển các tính năng nâng cao: Gợi ý tài liệu, phân tích xu hướng nghiên cứu và hỗ trợ viết tổng quan (Literature Review). "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/1-worklog/1.2-week2/","title":"Nhật ký Tuần 2","tags":[],"description":"","content":"Mục tiêu Tuần 2: Hiểu AWS Budgets và cách sử dụng để quản lý, giám sát chi phí AWS. Nắm được các loại Budget: Cost Budget, Usage Budget, RI Budget, Savings Plans Budget. Thực hành tạo Budget bằng Template, tự cấu hình và dọn dẹp (clean up) tài nguyên sau khi xong. Hiểu dịch vụ AWS Support: các gói hỗ trợ, cách truy cập, cách tạo và quản lý yêu cầu hỗ trợ (support case). Nâng cao ý thức về kiểm soát chi phí và quy trình nhờ AWS hỗ trợ khi có sự cố. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Tìm hiểu tổng quan AWS Budgets + AWS Budgets là gì? + Lý do cần sử dụng Budget để kiểm soát chi phí + Các loại Budget: Cost, Usage, RI, Savings Plans 09/16/2025 09/16/2025 https://000007.awsstudygroup.com/ 2 - Thực hành Budgets (1): + Tạo Budget bằng Template + Tạo Cost Budget với ngưỡng cảnh báo (threshold) + Xem chi tiết Budget và cấu hình thông báo 09/17/2025 09/17/2025 https://000007.awsstudygroup.com/ 3 - Thực hành Budgets (2): + Tạo Usage Budget cho một dịch vụ cụ thể (ví dụ: EC2) + Tạo RI Budget + Hiểu khi nào nên dùng từng loại Budget 09/18/2025 09/18/2025 https://000007.awsstudygroup.com/ 4 - Thực hành Budgets (3): + Tạo Savings Plans Budget + Xem cách Budget gửi cảnh báo khi chi phí vượt ngưỡng + Thực hiện Clean Up: xoá các Budget / tài nguyên không cần sau khi hoàn thành workshop 09/19/2025 09/19/2025 https://000007.awsstudygroup.com/ 5 - Tìm hiểu AWS Support: + Các gói hỗ trợ (Support Plans) và sự khác nhau giữa chúng + Cách truy cập AWS Support Center - Thực hành: + Vào Support Center + Tạo một support case + Xem, cập nhật, đóng yêu cầu hỗ trợ 09/20/2025 09/20/2025 https://000009.awsstudygroup.com/ Thành tựu Tuần 2: Hiểu rõ AWS Budgets là gì và cách hỗ trợ quản lý chi phí AWS. Phân biệt được các loại Budget: Cost, Usage, RI và Savings Plans, và khi nào nên áp dụng từng loại. Tạo thành công nhiều Budget khác nhau bằng Template và cấu hình chi tiết trong AWS Console. Thiết lập cảnh báo (alert) khi chi phí hoặc mức sử dụng vượt quá ngưỡng cho phép, giúp chủ động kiểm soát chi phí. Biết cách dọn dẹp (clean up) Budget và tài nguyên liên quan sau khi kết thúc bài thực hành. Nắm được mục đích của AWS Support và các gói hỗ trợ khác nhau. Thực hành truy cập Support Center, tạo mới, theo dõi và đóng một yêu cầu hỗ trợ (support case). Nâng cao nhận thức về quản lý chi phí và quy trình hỗ trợ khi vận hành hệ thống trên AWS. "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/5-workshop/5.2-preparation/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"Yêu cầu Tiên quyết Các yêu cầu cần có để thực hiện workshop này:\nMáy tính khách AWS: Được cấu hình với quyền truy cập vào các dịch vụ AWS cần thiết Môi trường phát triển: Windows, macOS hoặc Linux với các công cụ development cơ bản Kiến thức cơ bản: Hiểu biết về AWS, Python, JavaScript và Docker Tài khoản GitHub: Để clone source code và theo dõi changes Ngân sách AWS: Khoảng $65/tháng cho các resources (EC2, Bedrock, NAT Gateway) Cài đặt công cụ 1. AWS CLI AWS Command Line Interface (AWS CLI) là công cụ để tương tác với AWS services.\nWindows:\n# Download và cài đặt MSI installer msiexec.exe /i https://awscli.amazonaws.com/AWSCLIV2.msi macOS:\nbrew install awscli Linux:\ncurl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install Verify installation:\naws --version # aws-cli/2.x.x Python/3.x.x 2. Terraform Terraform là công cụ Infrastructure as Code để provision AWS resources.\nWindows:\nchoco install terraform macOS:\nbrew tap hashicorp/tap brew install hashicorp/tap/terraform Linux:\nwget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg echo \u0026#34;deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\u0026#34; | sudo tee /etc/apt/sources.list.d/hashicorp.list sudo apt update \u0026amp;\u0026amp; sudo apt install terraform Verify:\nterraform --version 3. Docker Docker để chạy Qdrant vector database locally và trên EC2.\nWindows/macOS: Download Docker Desktop\nLinux:\ncurl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh sudo usermod -aG docker $USER Verify:\ndocker --version docker run hello-world 4. Node.js (\u0026gt;= 18) Node.js cho frontend development với React + Vite.\nSử dụng nvm (khuyến nghị):\n# Install nvm curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash # Install Node.js 18 nvm install 18 nvm use 18 Verify:\nnode --version # v18.x.x npm --version # 9.x.x 5. Python (\u0026gt;= 3.11) Python cho backend FastAPI application.\nWindows: Download từ python.org (chọn \u0026ldquo;Add to PATH\u0026rdquo;)\nmacOS:\nbrew install python@3.11 Linux:\nsudo apt update sudo apt install python3.11 python3.11-venv python3-pip Verify:\npython --version # Python 3.11.x pip --version 6. Git Git cho version control.\nWindows: Download từ git-scm.com\nmacOS:\nbrew install git Linux:\nsudo apt install git Verify:\ngit --version Clone Repository git clone https://github.com/CrystalJohn/ARC-project.git cd ARC-project Cấu hình AWS Credentials Tạo IAM User Đăng nhập AWS Console Navigate to IAM → Users → Create user User name: arc-workshop-user Attach policies: AmazonEC2FullAccess AmazonS3FullAccess AmazonDynamoDBFullAccess AmazonCognitoPowerUser AmazonSQSFullAccess AmazonTextractFullAccess AmazonBedrockFullAccess CloudWatchFullAccess IAMFullAccess Create access key → Download credentials Configure AWS CLI aws configure Nhập thông tin:\nAWS Access Key ID: AKIAXXXXXXXXXXXXXXXX AWS Secret Access Key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Default region name: ap-southeast-1 Default output format: json Verify:\naws sts get-caller-identity Kích hoạt Amazon Bedrock Models Request Model Access AWS Console → Amazon Bedrock → Model access Click Manage model access Chọn models: Anthropic - Claude 3.5 Sonnet (anthropic.claude-3-5-sonnet-20241022-v2:0) Cohere - Embed Multilingual v3 (cohere.embed-multilingual-v3) Click Request model access → Accept Terms → Submit Verify Access # Test Claude aws bedrock get-foundation-model \\ --model-identifier anthropic.claude-3-5-sonnet-20241022-v2:0 \\ --region ap-southeast-1 # Test Cohere aws bedrock get-foundation-model \\ --model-identifier cohere.embed-multilingual-v3 \\ --region ap-southeast-1 Expected: Status Access granted\nChuẩn bị Sample Documents Project có sẵn sample PDFs trong samples/:\nls samples/ # data-structures-sample.pdf # test-sample.pdf Yêu cầu documents Limit Value Format PDF (text-based hoặc scanned) Max size 50 MB Max pages 500 pages Recommended 10-100 pages Checklist Trước khi tiếp tục, đảm bảo:\nAWS CLI installed và configured Terraform installed Docker installed và running Node.js 18+ installed Python 3.11+ installed Git installed Repository cloned IAM user created với đủ permissions Bedrock models được approve (Claude + Cohere) Sample documents sẵn sàng "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Nâng cao hiệu quả đào tạo phân tích bộ gen vi khuẩn với Amazon WorkSpaces Tác giả: Satsawat Natakarnkitkul, Charlie Lee, và Sikharin Kongpaiboon\nNgày đăng: ngày 04 tháng 04 năm 2025|\nDanh mục: Amazon WorkSpaces, Education, Healthcare, Higher education, Public Sector | Permalink|\nCác hội thảo phân tích bộ gen vi khuẩn yêu cầu các công cụ bioinformatics chuyên biệt và sức mạnh tính toán lớn để xử lý dữ liệu giải trình tự. Khi Trung tâm Nghiên cứu Y khoa Siriraj lên kế hoạch tổ chức “Hội thảo Nanopore: chuỗi hội thảo tin sinh học về bộ gen vi khuẩn” cho hơn 60 nhà nghiên cứu, họ đã gặp phải thách thức phổ biến: làm thế nào để cung cấp môi trường tính toán hiệu suất cao, đồng nhất cho các phân tích bộ gen phức tạp. Amazon Web Services (AWS) đã giải quyết vấn đề này thông qua Amazon WorkSpaces, thay đổi cách Trung tâm Nghiên cứu Y khoa Siriraj cung cấp đào tạo thực hành về bộ gen vi khuẩn.\nBạn có thể sử dụng Amazon WorkSpaces để cấp phát các máy tính để bàn ảo trên nền tảng đám mây, gọi là WorkSpaces, cho người dùng của mình. Những máy tính để bàn này có thể chạy Microsoft Windows, Amazon Linux 2, Ubuntu Linux, Rocky Linux hoặc Red Hat Enterprise Linux. WorkSpaces loại bỏ nhu cầu mua sắm và triển khai phần cứng hoặc cài đặt phần mềm phức tạp. Bạn có thể nhanh chóng thêm hoặc bớt người dùng khi nhu cầu thay đổi. Người dùng có thể truy cập máy tính để bàn ảo của mình từ nhiều thiết bị hoặc trình duyệt web khác nhau. Với những lợi ích này, người dùng có thể làm việc hiệu quả mà không cần phải lo lắng về máy tính để bàn của họ.\nThách thức Các hội thảo đào tạo về bộ gen vi khuẩn do Trung tâm Nghiên cứu Y khoa Siriraj tổ chức thường gặp phải nhiều khó khăn tài nguyên tính toán, cài đặt phần mềm, cũng như khả năng tiếp cận và mở rộng cơ sở hạ tầng.\nMột trong những thách thức lớn nhất là sự khác biệt về cấu hình phần cứng giữa các học viên. Nhiều người dùng phải sử dụng laptop cá nhân với hệ điều hành, tốc độ xử lý, bộ nhớ khác nhau, dẫn đến hiệu suất không đồng đều. Sự khác biệt này thường gây ra lỗi hệ thống, tốc độ xử lý chậm và không thể chạy các phân tích genome đòi hỏi tài nguyên lớn hiệu quả.\nViệc cài đặt và cấu hình phần mềm là trở ngại chính. Các công cụ bioinformatics như EPI2ME, phổ biến trong việc lắp ráp và phân tích bộ gen vi khuẩn, yêu cầu các gói phụ thuộc (dependencies) và cấu hình đặc thù. Đảm bảo tương thích trên nhiều thiết bị khác nhau thường làm gián đoạn tiến độ, khiến giảng viên mất thời gian xử lý sự cố thay vì tập trung vào thực hành.\nXử lý dữ liệu bộ gen vi khuẩn cần máy tính mạnh mà phần đông học viên không có sẵn. Thiếu tài nguyên tính toán dẫn đến việc không hoàn thành bài tập, gây thất vọng và làm giảm hiệu quả học tập. Laptop cá nhân thường không đủ khả năng xử lý các phép tính phức tạp trong phân tích dữ liệu DNA, làm hạn chế việc thực hành.\nPhương pháp giảng dạy truyền thống cũng giới hạn số lượng học viên mà tổ chức có thể đào tạo. Nhiều tổ chức thiếu cơ sở hạ tầng cần thiết để đáp ứng nhu cầu đào tạo ngày càng tăng, đặc biệt cho các buổi đào tạo kết hợp hoặc trực tuyến.\nXây dựng môi trường học tập trên nền tảng đám mây Oxford Nanopore Centre of Excellence (Thái Lan), Yip In Tsoi ( Đối tác AWS) và AWS đã phối hợp khởi xướng và tổ chức một hội thảo nhằm giải quyết những thách thức cấp bách này trong đào tạo tin sinh học, đặc biệt liên quan đến giới hạn phần cứng, vấn đề tương thích phần mềm, và sức mạnh tính toán. Hội thảo hợp tác này sử dụng WorkSpaces như một môi trường tính toán tập trung trên đám mây cho tất cả học viên, cung cấp một môi trường học tập tiêu chuẩn trên đám mây. WorkSpaces là dịch vụ máy tính để bàn ảo được quản lý toàn phần, cung cấp tài nguyên tính toán đã được cấu hình sẵn, giúp đảm bảo mọi học viên có cùng môi trường làm việc.\nMột trong những lợi ích chính của WorkSpaces là loại bỏ sự trì hoãn do cài đặt và cấu hình phần mềm. Tất cả các công cụ bioinformatics cần thiết cho hội thảo—bao gồm EPI2ME—đã được cài đặt sẵn và tối ưu, giúp học viên bắt đầu thực hành ngay lập tức.\nSức mạnh tính toán của WorkSpaces đóng vai trò quan trọng nâng cao trải nghiệm hội thảo. Nhờ truy cập nguồn tài nguyên đám mây mạnh mẽ, học viên có thể thực hiện lắp ráp bộ gen, căn chỉnh trình tự, và phân tích so sánh genome mà không gặp giới hạn về hiệu suất. Sự đồng đều trong tài nguyên tính toán giúp mọi học viên hoàn thành bài tập cùng tiến độ, tạo môi trường học tập hiệu quả hơn.\nKhả năng mở rộng và tiếp cận cũng là điểm mạnh của WorkSpaces. Học viên có thể đăng nhập WorkSpaces từ bất kỳ thiết bị nào, loại bỏ giới hạn về địa lý và phần cứng. Tính linh hoạt của WorkSpaces cũng giúp tổ chức dễ dàng đáp ứng số lượng học viên lớn mà không phải lo lắng về hạ tầng tính toán.\nKết quả hội thảo Trong ba ngày hội thảo, WorkSpaces được sử dụng rộng rãi. Học viên tham gia các bài tập như giải trình tự bằng công nghệ Oxford Nanopore (ONT), lắp ráp bộ gen bằng EPI2ME, và phân tích so sánh bộ gen gồm cgMLST và nghiên cứu ổ dịch.\nViệc triển khai WorkSpaces giúp hội thảo diễn ra suôn sẻ mà không gặp khó khăn kỹ thuật, cải thiện đáng kể so với các lần trước khi việc cài đặt và khắc phục lỗi có thể mất đến 3 giờ đồng hồ. Hiệu suất tính toán được giữ ổn định, giúp học viên tập trung phân tích dữ liệu thay vì gặp sự cố hoặc xử lý chậm.\nPhản hồi từ học viên cho thấy WorkSpaces đã giúp nâng cao hiệu quả đào tạo tin sinh học. Nhiều học viên cho biết môi trường tính toán tiêu chuẩn giúp họ tập trung vào nội dung học mà không phải lo ngại về hạn chế phần cứng hay lỗi phần mềm. Giảng viên cũng nhận thấy hiệu quả giảng dạy được cải thiện rõ rệt khi không phải mất thời gian xử lý các vấn đề kỹ thuật.\nTương lai phát triển Việc tích hợp thành công WorkSpaces với hội thảo Nanopore cho thấy công nghệ đám mây có thể thay đổi cách đào tạo. Bởi vì các rào cản công nghệ truyền thống đã được loại bỏ, học viên có thể tập trung hơn vào phân tích bộ gen vi khuẩn.\nTrong tương lai, có tiềm năng mở rộng sử dụng WorkSpaces trong các chương trình đào tạo genomics khác—đặc biệt là các dự án quy mô lớn—như:\nNâng cao khả năng phân tích bộ gen với AWS HealthOmics Xử lý và phân tích bộ dữ liệu lớn với AWS Batch Tự động hóa quy trình phân tích genome với AWS Lambda Những giải pháp này có thể cải thiện hơn nữa giáo dục tin sinh học bằng cách tối ưu hóa quy trình phân tích dữ liệu. Các tổ chức cũng đang nghiên cứu tích hợp WorkSpaces vào các mô hình học từ xa, giúp mở rộng sự tham gia của sinh viên và nhà nghiên cứu trên toàn cầu.\nĐể tìm hiểu thêm và bắt đầu, hãy liên hệ với nhóm tài khoản AWS của bạn hoặc nhóm hỗ trợ AWS Public Sector team.\nTài nguyên bổ sung Genomics on AWS Amazon WorkSpaces Documentation Siriraj Long-read Lab (Si-LoL), Oxford Nanopore Centre of Excellence (Thailand) Được đồng viết bởi Oxford Nanopore Centre of Excellence (Thailand), YIP In Tsoi (Đối tác AWS), và AWS.\nTAGS : Amazon Workspaces,AWS education,AWS for higher education,AWS healthcare, genomics, healthcare\nTác giả: Satsawat Natakarnkitkul: Trưởng nhóm dữ liệu và AI cho khu vực ASEAN tại AWS Thái Lan, dẫn dắt các sáng kiến AI tạo sinh trên khắp Đông Nam Á. Với hơn một thập kỷ kinh nghiệm trong chuyển đổi số và các giải pháp AI/ML, ông là chuyên gia đầu ngành trong trí tuệ nhân tạo, khoa học dữ liệu, và kiến trúc đám mây. Ông thường xuyên phát biểu tại các sự kiện công nghệ khu vực ASEAN, và nhiệt huyết sử dụng công nghệ mới như AI tạo sinh để tạo giá trị thực tế trong khu vực công.\nCharlie Lee: Chuyên gia hàng đầu về ngành genomics khu vực châu Á - Thái Bình Dương và Nhật Bản của AWS, có bằng tiến sĩ khoa học máy tính chuyên sâu về tin sinh học. Ông là nhà lãnh đạo trong lĩnh vực tin sinh học, genomics, và chẩn đoán phân tử, đam mê thúc đẩy nghiên cứu và cải thiện chăm sóc sức khỏe qua genomics với các công nghệ giải trình tự tiên tiến và điện toán đám mây.\nSikharin Kongpaiboon: Kiến trúc sư giải pháp tại AWS, hỗ trợ khách hàng hiểu và áp dụng tốt nhất các giải pháp đám mây, tối ưu triển khai. Ông phối hợp chặt chẽ với khách hàng để thiết kế kiến trúc đám mây có khả năng mở rộng, linh hoạt, và chịu lỗi cao, giúp giải quyết các thách thức kinh doanh và tăng tính nhanh nhẹn, hiệu quả, và an toàn.\nCác tài nguyên: AWS in the Public Sector\nAWS for Government\nAWS for Education\nAWS for Nonprofits\nAWS for Public Sector Health\nAWS for Aerospace and Satellite Solutions\nCase Studies\nFix This Podcast\nAdditional Resources\nContact Us\n"},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/3-blogstranslated/","title":"Translated Blogs","tags":[],"description":"","content":"Tại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Tăng cường deployment guardrails với tính năng rolling update cho inference component trên Amazon SageMaker AI inference Amazon SageMaker AI hiện đã hỗ trợ triển khai cuộn (rolling updates) cho inference components, giúp giải quyết các vấn đề chính của mô hình triển khai blue/green truyền thống—như chi phí GPU cao, hạn chế về dung lượng và rủi ro khi chuyển toàn bộ lưu lượng cùng lúc—đặc biệt đối với các mô hình LLM lớn chạy trên những phiên bản GPU đắt tiền. Inference component vốn đã giúp tối ưu bằng cách “right-size” tài nguyên và mở rộng theo từng mô hình, và rolling updates mở rộng lợi ích này bằng cách cập nhật các bản sao của mô hình theo từng lô có thể cấu hình, chỉ tạm thời bổ sung vừa đủ tài nguyên cho mỗi bước, chuyển lưu lượng sang phiên bản mới rồi giải phóng dần tài nguyên của phiên bản cũ. Bạn có thể kiểm soát kích thước batch, thời gian chờ, chiến lược rollback và khoảng thời gian đợi giữa các bước thông qua RollingUpdatePolicy trong UpdateInferenceComponent, trong khi các cảnh báo CloudWatch có thể kích hoạt rollback tự động, có kiểm soát nếu có sự cố xảy ra. Ví dụ, với ba phiên bản đơn GPU, SageMaker có thể cập nhật từng bản sao một bằng cách khởi chạy một instance mới, xác thực hoạt động, rồi loại bỏ một bản sao cũ, lặp lại cho đến khi tất cả được cập nhật—đạt được khả năng không gián đoạn dịch vụ, kiểm thử an toàn hơn và triển khai tiết kiệm chi phí, đáng tin cậy hơn cho nhiều kích cỡ mô hình khác nhau.\nBlog 2 - Nâng cao hiệu quả đào tạo phân tích bộ gen vi khuẩn với Amazon WorkSpaces Trung tâm Nghiên cứu Y khoa Siriraj với chuỗi hội thảo “Nanopore workshop: bacterial genome bioinformatics series” cần môi trường tính toán mạnh mẽ, đồng nhất cho hơn 60 nhà nghiên cứu, nhưng gặp phải nhiều trở ngại lớn: người tham gia sử dụng laptop cá nhân rất khác nhau về hệ điều hành, cấu hình CPU và RAM, nhiều máy không đủ mạnh cho các tác vụ phân tích bộ gen vi khuẩn nặng; việc cài đặt và cấu hình các công cụ tin sinh học phức tạp như EPI2ME trên từng thiết bị cá nhân tốn thời gian và dễ phát sinh lỗi; và hạ tầng tại chỗ hạn chế khiến việc mở rộng quy mô hay hỗ trợ các buổi đào tạo hybrid/online gặp nhiều khó khăn. Bằng cách sử dụng Amazon WorkSpaces—các desktop ảo trên đám mây có thể chạy nhiều hệ điều hành Windows hoặc Linux khác nhau và truy cập từ nhiều thiết bị—họ có thể cung cấp tập trung các môi trường mạnh, được cấu hình sẵn, tránh nhu cầu mua sắm phần cứng và cài đặt riêng lẻ cho từng người, từ đó mang lại trải nghiệm đào tạo thực hành về vi sinh bộ gen mượt mà, linh hoạt và dễ mở rộng hơn.\nBlog 3 - Thông báo kết thúc hỗ trợ và khả năng khám phá nâng cao cho Amazon EKS Trong thế giới ứng dụng container hóa đang phát triển nhanh chóng, việc duy trì khả năng chịu lỗi (resilience) và quan sát (observability) trên các môi trường Kubernetes trở thành một thách thức quan trọng. Khi các tổ chức ngày càng sử dụng Amazon Elastic Kubernetes Service (Amazon EKS) để quản lý khối lượng công việc chạy trên container, nhu cầu về quản lý vòng đời phiên bản cụm (cluster version lifecycle) và cơ chế khám phá (discovery) trở nên thiết yếu. Khi các môi trường Amazon EKS ngày càng phức tạp và mở rộng ra nhiều Vùng (Region) và tài khoản AWS khác nhau, người dùng thường gặp khó khăn trong việc theo dõi phiên bản cụm, vòng đời hỗ trợ và trạng thái triển khai tổng thể.\nViệc giám sát chủ động vòng đời và thời điểm kết thúc hỗ trợ của các cụm EKS là rất quan trọng để đảm bảo tính bảo mật, ổn định và tuân thủ cho các triển khai Kubernetes. Bên cạnh đó, việc có được khả năng quan sát rõ ràng đối với các cụm EKS trên toàn bộ một AWS Organization là điều cần thiết cho quản lý tài nguyên hiệu quả, lập kế hoạch chiến lược và duy trì một “inventory” chính xác.\n"},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Tăng cường deployment guardrails với tính năng rolling update cho inference component trên Amazon SageMaker AI inference Bài viết này có đồng tác giả là : Melanie Li, Andrew Smith, Dustin Liu, Vivek Gangasani, Shikhar Mishra, và June Won\nNgày: 25 tháng 3, 2025 | in Amazon SageMaker, Amazon SageMaker AI, Intermediate (200) Permalink | Comments | Share\nTriển khai các mô hình một cách hiệu quả, tin cậy và tiết kiệm chi phí là một thách thức quan trọng đối với các tổ chức ở mọi quy mô. Khi ngày càng nhiều tổ chức triển khai các foundation model (FM) và các mô hình machine learning (ML) khác vào môi trường production, họ phải đối mặt với những thách thức liên quan đến việc tận dụng tài nguyên, hiệu quả chi phí và duy trì tính khả dụng cao trong quá trình cập nhật. Amazon SageMaker AI đã giới thiệu chức năng inference component có thể giúp các tổ chức giảm chi phí triển khai mô hình bằng cách tối ưu hóa việc sử dụng tài nguyên thông qua khả năng đóng gói và mở rộng mô hình thông minh. Inference component trừu tượng hóa các mô hình ML và cho phép phân bổ tài nguyên chuyên dụng cũng như các chính sách mở rộng cụ thể cho từng mô hình.\nTuy nhiên, việc cập nhật các mô hình này—đặc biệt trong môi trường production với các SLA về độ trễ nghiêm ngặt—về mặt lịch sử có nguy cơ gây downtime hoặc tắc nghẽn tài nguyên. Các triển khai blue/green truyền thống thường gặp khó khăn với những hạn chế về năng lực, khiến việc cập nhật trở nên khó dự đoán đối với các mô hình sử dụng GPU nặng. Để giải quyết vấn đề này, chúng tôi rất vui mừng công bố một cải tiến mạnh mẽ khác cho RageMaker AI:tính năng rolling update cho inference component endpoint, một tính năng được thiết kế để đơn giản hóa việc cập nhật cho các mô hình có kích thước khác nhau đồng thời giảm thiểu chi phí vận hành.\nTrong bài viết này, chúng tôi thảo luận về những thách thức mà các tổ chức phải đối mặt khi cập nhật mô hình trong production. Sau đó, chúng tôi đi sâu vào tính năng rolling update mới cho inference component và cung cấp các ví dụ thực tế sử dụng các mô hình DeepSeek distilled để minh họa tính năng này. Cuối cùng, chúng tôi khám phá cách thiết lập rolling update trong các tình huống khác nhau.\nNhững thách thức với triển khai blue/green Theo truyền thống, RageMaker AI inference đã hỗ trợ mô hình triển khai blue/green để cập nhật inference component trong production. Mặc dù có hiệu quả trong nhiều tình huống, cách tiếp cận này đi kèm với những thách thức cụ thể:\nKém hiệu quả về tài nguyên – Triển khai blue/green yêu cầu cung cấp tài nguyên cho cả môi trường hiện tại (blue) và môi trường mới (green) đồng thời. Đối với các inference component chạy trên các GPU instance đắt tiền như P4d hoặc G5, điều này có nghĩa là có khả năng tăng gấp đôi yêu cầu tài nguyên trong quá trình triển khai. Hãy xem xét một ví dụ trong đó khách hàng có 10 bản sao của một inference component phân bố trên 5 instance ml.p4d.24xlarge, tất cả đều hoạt động với công suất đầy đủ. Với triển khai blue/green, SageMaker AI sẽ cần cung cấp thêm năm instance ml.p4d.24xlarge để lưu trữ phiên bản mới của inference component trước khi chuyển đổi lưu lượng và ngừng sử dụng các instance cũ. Tài nguyên tính toán hạn chế – Đối với khách hàng sử dụng các GPU instance mạnh mẽ như dòng P hoặc G, năng lực cần thiết có thể không có sẵn trong một Availability Zone hoặc Region nhất định. Điều này thường dẫn đến các ngoại lệ về năng lực instance trong quá trình triển khai, gây ra lỗi cập nhật và rollback. Chuyển đổi theo kiểu tất cả hoặc không có gì – Các triển khai blue/green truyền thống chuyển toàn bộ lưu lượng cùng một lúc hoặc dựa trên lịch trình được cấu hình. Điều này để lại không gian hạn chế cho việc xác thực dần dần và tăng phạm vi ảnh hưởng nếu có vấn đề phát sinh với triển khai mới. Mặc dù triển khai blue/green đã là một chiến lược đáng tin cậy cho các bản cập nhật zero-downtime, những hạn chế của nó trở nên rõ ràng khi triển khai các large language model (LLM) quy mô lớn hoặc các mô hình thông lượng cao trên các GPU instance cao cấp. Những thách thức này đòi hỏi một cách tiếp cận tinh tế hơn—một cách tiếp cận xác thực các bản cập nhật từng bước trong khi tối ưu hóa việc sử dụng tài nguyên. Rolling update cho inference component được thiết kế để loại bỏ sự cứng nhắc của các triển khai blue/green. Bằng cách cập nhật các mô hình theo các batch được kiểm soát, mở rộng cơ sở hạ tầng một cách linh hoạt và tích hợp các kiểm tra an toàn theo thời gian thực, chiến lược này đảm bảo các triển khai vẫn tiết kiệm chi phí, đáng tin cậy và có khả năng thích ứng—ngay cả đối với các workload sử dụng GPU nặng.\nRolling deployment để cập nhật inference component Như đã đề cập trước đó, inference component được giới thiệu như một tính năng của RageMaker AI để tối ưu hóa chi phí; chúng cho phép bạn định nghĩa và triển khai các tài nguyên cụ thể cần thiết cho workload suy luận mô hình của bạn. Bằng cách điều chỉnh đúng kích thước tài nguyên tính toán để phù hợp với yêu cầu của mô hình, bạn có thể tiết kiệm chi phí trong quá trình cập nhật so với các phương pháp triển khai truyền thống.\nVới rolling update, RageMaker AI triển khai các phiên bản mô hình mới theo các batch inference component có thể cấu hình trong khi mở rộng instance một cách linh hoạt. Điều này đặc biệt có tác động đối với các LLM:\nTính linh hoạt về kích thước batch – Khi cập nhật các inference component trong một SageMaker AI endpoint, bạn có thể chỉ định kích thước batch cho mỗi bước rolling. Đối với mỗi bước, RageMaker AI cung cấp năng lực dựa trên kích thước batch được chỉ định trên endpoint fleet mới, định tuyến lưu lượng đến fleet đó và dừng năng lực trên endpoint fleet cũ. Các mô hình nhỏ hơn như DeepSeek Distilled Llama 8B có thể sử dụng các batch lớn hơn để cập nhật nhanh chóng, và các mô hình lớn hơn như DeepSeek Distilled Llama 70B sử dụng các batch nhỏ hơn để hạn chế tranh chấp GPU. Bảo vệ an toàn tự động – Các alarm Amazon CloudWatch tích hợp giám sát các metric trên một inference component. Bạn có thể cấu hình các alarm để kiểm tra xem phiên bản mới được triển khai của inference component có hoạt động đúng hay không. Nếu các alarm CloudWatch được kích hoạt, RageMaker AI sẽ bắt đầu một rollback tự động. Chức năng mới được triển khai thông qua các phần mở rộng cho RageMaker AI API, chủ yếu với các tham số mới trong API Update Inference Component:\nsagemaker_client.update_inference_component(\nInferenceComponentName=inference_component_name,\nRuntimeConfig={ \u0026ldquo;CopyCount\u0026rdquo;: number },\nSpecification={ \u0026hellip; },\nDeploymentConfig={\n\u0026ldquo;RollingUpdatePolicy\u0026rdquo;: {\n\u0026ldquo;MaximumBatchSize\u0026rdquo;: { # Value must be between 5% to 50% of the IC\u0026rsquo;s total copy count.\n\u0026ldquo;Type\u0026rdquo;: \u0026ldquo;COPY_COUNT\u0026rdquo;, # COPY_COUNT | CAPACITY_PERCENT\n\u0026ldquo;Value\u0026rdquo;: 1 # Minimum value of 1\n},\n\u0026ldquo;MaximumExecutionTimeoutInSeconds\u0026rdquo;: 600, #Minimum value of 600. Maximum value of 28800.\n\u0026ldquo;RollbackMaximumBatchSize\u0026rdquo;: {\n\u0026ldquo;Type\u0026rdquo;: \u0026ldquo;COPY_COUNT\u0026rdquo;, # COPY_COUNT | CAPACITY_PERCENT\n\u0026ldquo;Value\u0026rdquo;:1\n},\n\u0026ldquo;WaitIntervalInSeconds\u0026rdquo;: 120 # Minimum value of 0. Maximum value of 3600\n}\n},\nAutoRollbackConfiguration={\n\u0026ldquo;Alarms\u0026rdquo;: [\n{\n\u0026ldquo;AlarmName\u0026rdquo;: \u0026ldquo;string\u0026rdquo; #Optional\n}\n]\n},\n)\nĐoạn code trên sử dụng các tham số sau:\nMaximumBatchSize – Đây là một tham số bắt buộc và định nghĩa kích thước batch cho mỗi bước rolling trong quy trình triển khai. Đối với mỗi bước, RageMaker AI cung cấp năng lực trên endpoint fleet mới, định tuyến lưu lượng đến fleet đó và dừng năng lực trên endpoint fleet cũ. Giá trị phải nằm trong khoảng từ 5–50% số lượng bản sao của inference component. Type – Tham số này có thể chứa một giá trị như COPY_COUNT | CAPACITY_PERCENT, chỉ định loại năng lực endpoint. Value – Định nghĩa kích thước năng lực, dưới dạng số lượng bản sao inference component hoặc phần trăm năng lực. MaximumExecutionTimeoutSeconds – Đây là thời gian tối đa mà rolling deployment sẽ dành cho việc thực thi tổng thể. Vượt quá giới hạn này sẽ gây ra timeout. RollbackMaximumBatchSize – Đây là kích thước batch cho một rollback về endpoint fleet cũ. Nếu trường này vắng mặt, giá trị được đặt thành mặc định, là 100% tổng năng lực. Khi sử dụng mặc định, RageMaker AI cung cấp toàn bộ năng lực của fleet cũ cùng một lúc trong quá trình rollback. Value – Tham số Value của cấu trúc này sẽ chứa giá trị mà Type sẽ được thực thi. Đối với chiến lược rollback, nếu bạn không chỉ định các trường trong đối tượng này, hoặc nếu bạn đặt Value thành 100%, thì SageMaker AI sử dụng chiến lược rollback blue/green và roll lưu lượng trở lại fleet blue. WithIntervalInSeconds – Đây là giới hạn thời gian cho tổng triển khai. Vượt quá giới hạn này sẽ gây ra timeout. AutoRollbackConfiguration – Đây là cấu hình rollback tự động để xử lý lỗi triển khai endpoint và khôi phục. AlarmName – Alarm CloudWatch này được cấu hình để giám sát các metric trên một InferenceComponent Bạn có thể cấu hình nó để kiểm tra xem phiên bản mới được triển khai của InferenceComponent có hoạt động đúng hay không. Để biết thêm thông tin về SageMaker AI API, tham khảo SageMaker AI API Reference.\nTrải nghiệm khách hàng Hãy cùng khám phá cách rolling update hoạt động trong thực tế với một số tình huống phổ biến, sử dụng các LLM có kích thước khác nhau. Bạn có thể tìm thấy notebook ví dụ trong GitHub repo.\nTình huống 1: Nhiều cluster GPU đơn Trong tình huống này, giả sử bạn đang chạy một endpoint với ba instance ml.g5.2xlarge, mỗi instance có một GPU duy nhất. Endpoint lưu trữ một inference component yêu cầu một CPU accelerator, có nghĩa là mỗi instance chứa một bản sao. Khi bạn muốn cập nhật inference component để sử dụng phiên bản inference component mới, bạn có thể sử dụng rolling update để giảm thiểu sự gián đoạn.\nBạn có thể cấu hình một rolling update với kích thước batch là một, có nghĩa là RageMaker AI sẽ cập nhật từng bản sao một. Trong quá trình cập nhật, RageMaker AI trước tiên xác định năng lực có sẵn trong các instance hiện có. Vì không có instance hiện tại nào có không gian cho các workload tạm thời bổ sung, RageMaker AI sẽ khởi chạy các instance ml.g5.2xlarge mới từng cái một để triển khai một bản sao của phiên bản inference component mới lên một GPU instance. Sau khoảng thời gian chờ được chỉ định và container của inference component mới vượt qua kiểm tra healthy, RageMaker AI loại bỏ một bản sao của phiên bản cũ (vì mỗi bản sao được lưu trữ trên một instance, instance này sẽ được dỡ bỏ tương ứng), hoàn tất bản cập nhật cho batch đầu tiên.\nQuy trình này lặp lại cho bản sao thứ hai của inference component, cung cấp một quá trình chuyển đổi suôn sẻ với zero downtime. Bản chất dần dần của bản cập nhật giảm thiểu rủi ro và cho phép bạn duy trì tính khả dụng nhất quán trong suốt quy trình triển khai. Sơ đồ sau đây cho thấy quy trình này.\nTình huống 2: Cập nhật với rollback tự động Trong một tình huống khác, bạn có thể đang cập nhật inference component của mình từ Llama-3.1-8B-Instruct sang DeepSeek-R1-Distill-Llama-8B, nhưng phiên bản mô hình mới có các kỳ vọng API khác nhau. Trong trường hợp sử dụng này, bạn đã cấu hình một alarm CloudWatch để giám sát lỗi 4xx, điều này sẽ cho biết các vấn đề về tương thích API.\nBạn có thể bắt đầu một rolling update với kích thước batch là một bản sao. RageMaker AI triển khai bản sao đầu tiên của phiên bản mới trên một GPU instance mới. Khi instance mới sẵn sàng phục vụ lưu lượng, RageMaker AI sẽ chuyển tiếp một phần các yêu cầu invocation đến mô hình mới này. Tuy nhiên, trong ví dụ này, phiên bản mô hình mới, đang thiếu cấu hình biến môi trường \u0026ldquo;MESSAGES_API_ENABLED\u0026rdquo;, sẽ bắt đầu trả về lỗi 4xx khi nhận các yêu cầu ở định dạng Messages API.\nAlarm CloudWatch được cấu hình phát hiện các lỗi này và chuyển sang trạng thái alarm. RageMaker AI tự động phát hiện trạng thái alarm này và bắt đầu quy trình rollback theo cấu hình rollback. Theo kích thước batch rollback được chỉ định, RageMaker AI loại bỏ phiên bản mô hình mới có vấn đề và duy trì phiên bản gốc đang hoạt động, ngăn chặn sự gián đoạn dịch vụ trên diện rộng. Endpoint trở về trạng thái ban đầu với lưu lượng được xử lý bởi phiên bản mô hình gốc hoạt động đúng.\nĐoạn code sau đây cho thấy cách thiết lập một alarm CloudWatch để giám sát lỗi 4xx:\nCreate alarm cloudwatch.put_metric_alarm(\nAlarmName=f\u0026rsquo;SageMaker-{endpoint_name}-4xx-errors',\nComparisonOperator=\u0026lsquo;GreaterThanThreshold\u0026rsquo;,\nEvaluationPeriods=1,\nMetricName=\u0026lsquo;Invocation4XXErrors\u0026rsquo;,\nNamespace=\u0026lsquo;AWS/SageMaker\u0026rsquo;,\nPeriod=300,\nStatistic=\u0026lsquo;Sum\u0026rsquo;,\nThreshold=5.0,\nActionsEnabled=True,\nAlarmDescription=\u0026lsquo;Alarm when greather than 5 4xx errors\u0026rsquo;,\nDimensions=[\n{\n\u0026lsquo;Name\u0026rsquo;: \u0026lsquo;InferenceComponentName\u0026rsquo;,\n\u0026lsquo;Value\u0026rsquo;: inference_component_name\n},\n],\n)\nSau đó bạn có thể sử dụng alarm CloudWatch này trong yêu cầu cập nhật:\nDeploymentConfig={\n\u0026ldquo;RollingUpdatePolicy\u0026rdquo;: {\n\u0026ldquo;MaximumBatchSize\u0026rdquo;: {\n\u0026ldquo;Type\u0026rdquo;: \u0026ldquo;COPY_COUNT\u0026rdquo;,\n\u0026ldquo;Value\u0026rdquo;: 1\n},\n\u0026ldquo;WaitIntervalInSeconds\u0026rdquo;: 120,\n\u0026ldquo;RollbackMaximumBatchSize\u0026rdquo;: {\n\u0026ldquo;Type\u0026rdquo;: \u0026ldquo;COPY_COUNT\u0026rdquo;,\n\u0026ldquo;Value\u0026rdquo;: 1\n}\n},\n\u0026lsquo;AutoRollbackConfiguration\u0026rsquo;: {\n\u0026ldquo;Alarms\u0026rdquo;: [\n{\u0026ldquo;AlarmName\u0026rdquo;: f\u0026rsquo;SageMaker-{endpoint_name}-4xx-errors\u0026rsquo;}\n]\n}\n}\nTình huống 3: Cập nhật với năng lực đầy đủ trong các instance hiện có Nếu một endpoint hiện có có nhiều GPU accelerator và không phải tất cả các accelerator đều được sử dụng, bản cập nhật có thể sử dụng các GPU accelerator hiện có mà không cần khởi chạy các instance mới cho endpoint. Xem xét nếu bạn có một endpoint được cấu hình với hai instance ml.g5.12xlarge ban đầu có bốn GPU accelerator trong mỗi instance. Endpoint lưu trữ hai inference component: IC-1 yêu cầu một accelerator và IC-2 cũng yêu cầu một accelerator. Trên một instance ml.g5.12xlarge, có bốn bản sao của IC-1 đã được tạo; trên instance khác, hai bản sao của IC-2 đã được tạo. Vẫn còn hai GPU accelerator có sẵn trên instance thứ hai.\nKhi bạn bắt đầu một bản cập nhật cho IC-1 với kích thước batch là hai bản sao, RageMaker AI xác định rằng có đủ năng lực trong các instance hiện có để lưu trữ các phiên bản mới trong khi duy trì các phiên bản cũ. Nó sẽ tạo hai bản sao của phiên bản IC-1 mới trên instance thứ hai. Khi các container đã khởi động và chạy, SageMaker AI sẽ hướng lưu lượng đến các IC-1 mới và sau đó bắt đầu định tuyến lưu lượng đến các inference component mới. RageMaker AI cũng sẽ loại bỏ hai trong số các bản sao IC-1 cũ khỏi instance. Bạn không bị tính phí cho đến khi các inference component mới bắt đầu nhận các invocation và tạo ra các phản hồi.\nBây giờ có thêm hai GPU slot trống. RageMaker AI sẽ cập nhật batch thứ hai, và nó sẽ sử dụng các GPU accelerator trống vừa có sẵn. Sau khi các quy trình hoàn tất, endpoint có bốn IC-1 với phiên bản mới và hai bản sao của IC-2 không bị thay đổi.\nTình huống 4: Cập nhật yêu cầu năng lực instance bổ sung Xem xét nếu bạn có một endpoint được cấu hình với ban đầu một instance ml.g5.12xlarge (tổng cộng 4 GPU) và được cấu hình managed instance scaling (MIS) với số instance tối đa được đặt thành hai. Endpoint lưu trữ hai inference component: IC-1 yêu cầu 1 GPU với hai bản sao (Llama 8B), và IC-2 (mô hình DeepSeek Distilled Llama 14B) cũng yêu cầu 1 GPU với hai bản sao—sử dụng tất cả 4 GPU có sẵn.\nKhi bạn bắt đầu một bản cập nhật cho IC-1 với kích thước batch là hai bản sao, RageMaker AI xác định rằng không có đủ năng lực trong các instance hiện có để lưu trữ các phiên bản mới trong khi duy trì các phiên bản cũ. Thay vì làm thất bại bản cập nhật, vì bạn đã cấu hình MIS, RageMaker AI sẽ tự động cung cấp một instance g5.12.xlarge thứ hai để lưu trữ các inference component mới.\nTrong quá trình cập nhật, RageMaker AI triển khai hay bản sao của phiên bản IC-1 mới lên instance mới được cung cấp, như được hiển thị trong sơ đồ sau. Sau khi các inference component mới đã khởi động và chạy, RageMaker AI bắt đầu loại bỏ các bản sao IC-1 cũ khỏi các instance gốc. Đến cuối bản cập nhật, instance đầu tiên sẽ lưu trữ IC-2 sử dụng 2 GPU, và instance thứ hai mới được cung cấp sẽ lưu trữ IC-1 đã cập nhật với hai bản sao sử dụng 2 GPU. Sẽ có các không gian mới có sẵn trong hai instance, và bạn có thể triển khai thêm các bản sao inference component hoặc các mô hình mới vào cùng một endpoint bằng cách sử dụng các tài nguyên GPU có sẵn. Nếu bạn thiết lập managed instance auto scaling và đặt inference component auto scaling về không, bạn có thể scale down các bản sao inference component về không, điều này sẽ dẫn đến instance tương ứng được scale down. Khi inference component được scale up, SageMaker AI sẽ khởi chạy các inference component trong instance hiện có với các GPU accelerator có sẵn, như đã đề cập trong tình huống 3.\nTình huống 5: Cập nhật đối mặt với năng lực không đủ Trong các tình huống không có đủ năng lực GPU, RageMaker AI cung cấp phản hồi rõ ràng về các ràng buộc năng lực. Xem xét nếu bạn có một endpoint chạy trên 30 instance ml.g6e.16xlarge, mỗi instance đã được sử dụng đầy đủ với các inference component. Bạn muốn cập nhật một inference component hiện có bằng cách sử dụng rolling deployment với kích thước batch là 4, nhưng sau khi bốn batch đầu tiên được cập nhật, không có đủ năng lực GPU có sẵn cho phần còn lại của bản cập nhật. Trong trường hợp này, RageMaker AI sẽ tự động rollback về thiết lập trước đó và dừng quy trình cập nhật.\nCó thể có hai trường hợp cho trạng thái cuối cùng của rollback này. Trong trường hợp đầu tiên, rollback đã thành công vì có năng lực mới có sẵn để khởi chạy các instance cho phiên bản mô hình cũ. Tuy nhiên, có thể có một trường hợp khác trong đó vấn đề năng lực vẫn tồn tại trong quá trình rolling back, và endpoint sẽ hiển thị là UPDATE_ROLLBACK_FAILED. Các instance hiện có vẫn có thể phục vụ lưu lượng, nhưng để chuyển endpoint ra khỏi trạng thái failed, bạn cần liên hệ với nhóm AWS support của mình.\nCác cân nhắc bổ sung Như đã đề cập trước đó, khi sử dụng triển khai blue/green để cập nhật các inference component trên một endpoint, bạn cần cung cấp tài nguyên cho cả môi trường hiện tại (blue) và môi trường mới (green) đồng thời. Khi bạn đang sử dụng rolling update cho các inference component trên endpoint, bạn có thể sử dụng phương trình sau để tính số lượng service quota tài khoản cho loại instance cần thiết. GPU instance cần thiết cho endpoint có X số GPU accelerator, và mỗi bản sao inference component yêu cầu Y số GPU accelerator. Kích thước batch tối đa được đặt thành Z và endpoint hiện tại có N instance. Do đó, service quota cấp tài khoản cần thiết cho loại instance này cho endpoint phải lớn hơn đầu ra của phương trình:\nROUNDUP(Z x Y / X) + N\nVí dụ, giả sử endpoint hiện tại có 8 (N) instance ml.g5.12xlarge, có 4 GPU accelerator của mỗi instance. Bạn đặt kích thước batch tối đa thành 2 (Z) bản sao, và mỗi bản sao cần 1 (Y) GPU accelerator. Giá trị service quota AWS tối thiểu cho ml.g5.12xlarge là ROUNDUP(2 x 1 / 4) + 8 = 9. Trong một tình huống khác, khi mỗi bản sao của inference component yêu cầu 4 GPU accelerator, thì service quota cấp tài khoản cần thiết cho cùng một instance phải là ROUNDUP(2 x 4 / 4) + 8 = 10.\nKết luận Các bản cập nhật cuốn chiếu (rolling updates) cho các thành phần suy luận đại diện cho một bước tiến quan trọng trong khả năng triển khai của SageMaker AI. Tính năng này trực tiếp giải quyết các thách thức trong việc cập nhật mô hình đang chạy trong môi trường sản xuất, đặc biệt là với những khối lượng công việc nặng về GPU. Nó giúp loại bỏ việc phải ước lượng dung lượng thủ công, đồng thời giảm thiểu rủi ro khi cần hoàn tác (rollback).\nBằng cách kết hợp quy trình cập nhật theo lô (batch-based updates) cùng với các biện pháp bảo vệ tự động, SageMaker AI đảm bảo rằng các quá trình triển khai luôn linh hoạt và ổn định.\nCác lợi ích chính bao gồm:\nGiảm chi phí tài nguyên trong quá trình triển khai, không cần cấp phát thêm cụm máy chủ dự phòng. Cải thiện cơ chế bảo vệ trong quá trình triển khai nhờ cập nhật dần và khả năng tự động hoàn tác khi xảy ra lỗi. Duy trì khả năng hoạt động liên tục trong khi cập nhật, với kích thước lô có thể cấu hình. Đơn giản hóa việc triển khai các mô hình phức tạp cần nhiều bộ tăng tốc (multi-accelerator models). Dù bạn đang triển khai mô hình nhỏ gọn hay các mô hình lớn sử dụng nhiều bộ tăng tốc, rolling updates mang lại một phương pháp hiệu quả hơn, tiết kiệm chi phí và an toàn hơn để giữ cho các mô hình máy học của bạn luôn được cập nhật trong môi trường sản xuất.\nChúng tôi khuyến khích bạn dùng thử khả năng mới này trên các endpointSageMaker AI của mình và khám phá cách nó có thể nâng cao hiệu quả hoạt động ML của bạn. Để biết thêm thông tin, vui lòng tham khảo SageMaker AI documentation hoặc liên hệ với nhóm tài khoản AWS của bạn.\nVề các tác giả Melanie Li, Tiến sĩ, là Chuyên gia Kiến trúc Giải pháp Generative AI Cấp cao tại AWS, trụ sở tại Sydney, Úc. Cô tập trung vào việc hỗ trợ khách hàng xây dựng các giải pháp ứng dụng các công cụ AI và máy học tiên tiến nhất. Cô đã tham gia vào nhiều sáng kiến Generative AI trên toàn khu vực APJ, tận dụng sức mạnh của Large Language Models (LLMs). Trước khi gia nhập AWS, Tiến sĩ Li từng đảm nhiệm vai trò nhà khoa học dữ liệu trong lĩnh vực tài chính và bán lẻ.\nAndrew Smith là Kỹ sư Hỗ trợ Đám mây trong nhóm SageMaker, Vision \u0026amp; Other tại AWS, trụ sở Sydney, Úc. Anh hỗ trợ khách hàng sử dụng nhiều dịch vụ AI/ML của AWS, đặc biệt có chuyên môn sâu về Amazon SageMaker. Ngoài công việc, anh thích dành thời gian cho gia đình, bạn bè và tìm hiểu các công nghệ mới.\nDustin Liu là Kiến trúc sư Giải pháp (Solutions Architect) tại AWS, tập trung hỗ trợ các công ty khởi nghiệp và doanh nghiệp SaaS trong lĩnh vực dịch vụ tài chính và bảo hiểm (FSI). Anh có nền tảng đa dạng trong kỹ thuật dữ liệu (data engineering), khoa học dữ liệu (data science) và máy học (machine learning), đồng thời đam mê ứng dụng AI/ML để thúc đẩy đổi mới và chuyển đổi doanh nghiệp.\nVivek Gangasani là Chuyên gia Kiến trúc Giải pháp Generative AI Cấp cao tại AWS. Anh giúp các công ty khởi nghiệp về Generative AI xây dựng các giải pháp sáng tạo bằng cách sử dụng dịch vụ AWS và hạ tầng tính toán tăng tốc. Hiện tại, anh tập trung vào việc phát triển các chiến lược tinh chỉnh (fine-tuning) và tối ưu hiệu năng suy luận (inference performance) cho các mô hình ngôn ngữ lớn (LLMs). Ngoài công việc, Vivek thích leo núi, xem phim và khám phá ẩm thực.\nShikher Mishra là Kỹ sư Phát triển Phần mềm (Software Development Engineer) thuộc nhóm SageMaker Inference, với hơn 9 năm kinh nghiệm trong ngành. Anh đam mê xây dựng các giải pháp mở rộng, hiệu quả, giúp khách hàng triển khai và quản lý ứng dụng máy học một cách dễ dàng. Thời gian rảnh, Shikher yêu thích thể thao ngoài trời, leo núi và du lịch.\nJune Won là Quản lý sản phẩm (Product Manager) của Amazon SageMaker JumpStart. Anh tập trung vào việc giúp khách hàng dễ dàng tìm kiếm và sử dụng các mô hình nền tảng (foundation models) để xây dựng ứng dụng Generative AI. Kinh nghiệm của anh tại Amazon còn bao gồm phát triển ứng dụng mua sắm di động và giải pháp giao hàng chặng cuối (last-mile delivery).\n"},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Thông báo kết thúc hỗ trợ và khả năng khám phá nâng cao cho Amazon EKS Ngày 05 tháng 03 năm 2025\nTác giả: Praseeda Sathaye (Principal Solutions Architect, Containers \u0026amp; OSS), AJ Davis (AWS Enterprise Support) và Arvind Viswanathan (Principal Solutions Architect)\nGiới thiệu Trong thế giới ứng dụng container hóa đang phát triển nhanh chóng, việc duy trì khả năng phục hồi và khả năng quan sát trên các môi trường Kubernetes đã trở thành một thách thức quan trọng. Khi các tổ chức ngày càng áp dụng Amazon Elastic Kubernetes Service (Amazon EKS) để quản lý khối lượng công việc container hóa của họ, nhu cầu về quản lý vòng đời phiên bản cluster và cơ chế khám phá trở nên cực kỳ quan trọng. Khi môi trường Amazon EKS trở nên phức tạp hơn và mở rộng trên nhiều AWS Regions và tài khoản, người dùng thường gặp khó khăn trong việc theo dõi phiên bản cluster, vòng đời hỗ trợ và trạng thái triển khai tổng thể.\nGiám sát chủ động vòng đời cluster EKS và kết thúc hỗ trợ là rất quan trọng để đảm bảo tính bảo mật, ổn định và tuân thủ của các triển khai Kubernetes. Hơn nữa, việc có được khả năng hiển thị các triển khai cluster EKS trên toàn bộ AWS Organization là điều cần thiết cho việc quản lý tài nguyên hiệu quả, lập kế hoạch chiến lược và duy trì bảng kiểm kê chính xác.\nTrong bài viết này, để giải quyết những điểm yếu này, chúng tôi chia sẻ hai giải pháp mạnh mẽ cung cấp khả năng quan sát các cluster EKS:\nThông báo kết thúc hỗ trợ Khám phá và báo cáo Giải pháp đầu tiên sử dụng AWS Health, Amazon EventBridge và Amazon Simple Notification Service (Amazon SNS)/Amazon Simple Queue Service (Amazon SQS) để giám sát các sự kiện cụ thể của Amazon EKS, đặc biệt đối với các cluster sắp kết thúc hỗ trợ (tiêu chuẩn và mở rộng). Việc cung cấp thông báo sớm khi một cluster EKS sắp kết thúc cửa sổ hỗ trợ cho phép giải pháp này trao quyền cho bạn chủ động lập kế hoạch và cập nhật phiên bản Kubernetes của cluster.\nBổ sung cho điều này, giải pháp thứ hai là một cơ chế khám phá và báo cáo tự động xác định và tổng hợp thông tin chi tiết về các cluster EKS trên tất cả các AWS Regions và tài khoản trong Organization của bạn. Khả năng hiển thị toàn diện này về các phiên bản cluster, tags liên quan và các chi tiết chính khác giúp kiểm tra tuân thủ, quản lý bảng kiểm kê tài nguyên chính xác và lập kế hoạch nâng cấp chiến lược.\nCùng nhau, hai giải pháp này cung cấp một framework mạnh mẽ để quản lý vòng đời cluster EKS hiệu quả, cho phép các tổ chức luôn đi trước các vấn đề tiềm ẩn, tối ưu hóa việc sử dụng tài nguyên và đưa ra các quyết định sáng suốt phù hợp với mục tiêu chiến lược dài hạn của họ.\nĐiều kiện tiên quyết Bạn cần những điều sau để hoàn thành hướng dẫn:\nMột AWS account với Organizations được bật Gói hỗ trợ Business, Enterprise On-Ramp hoặc Enterprise từ AWS Support để sử dụng AWS Health API Kiến thức cơ bản về Amazon EKS, AWS Health, EventBridge, AWS Lambda, AWS Identity and Access Management (IAM), Amazon S3, Amazon SNS, Amazon SQS và AWS Cloud Development Kit (AWS CDK) Khả năng ủy quyền từ tài khoản quản lý đến tài khoản tooling được sử dụng để tập trung thông báo và thực hiện khám phá cluster EKS trên toàn bộ Organization Kiến thức về Python Thiết lập ban đầu Các bước sau hướng dẫn bạn qua quá trình thiết lập ban đầu.\nBật AWS Health Organizational View trong tài khoản quản lý Bật Organizational View in AWS Health để có được chế độ xem tập trung, tổng hợp các sự kiện AWS Health trên toàn bộ Organization của bạn. Bạn có thể xác minh rằng điều này được bật thông qua console hoặc bằng cách chạy lệnh sau bằng AWS Command Line Interface (AWS CLI):\naws health describe-health-service-status-for-organization. Bạn sẽ thấy kết quả sau:\n{\u0026ldquo;healthServiceAccessStatusForOrganization\u0026rdquo;: \u0026ldquo;ENABLED\u0026rdquo; }\nGói hỗ trợ Business, Enterprise On-Ramp hoặc Enterprise từ AWS Support là cần thiết để sử dụng AWS Health API và hoàn thành bước này.\nỦy quyền quản trị từ tài khoản quản lý đến tài khoản tooling trung tâm Thiết lập một tài khoản AWS trong Organization làm tài khoản tooling cho giải pháp này. Tài khoản này được sử dụng để tập trung thông báo và khám phá.\nTừ tài khoản quản lý, ủy quyền quản trị AWS CloudFormation StackSets bằng cách làm theo các bước được mô tả trong bài viết này: CloudFormation StackSets delegated administration.\nKết quả tương tự cũng có thể đạt được bằng cách chạy lệnh sau từ tài khoản quản lý. Thay thế 012345678901 bằng AWS account ID của tài khoản tooling của bạn.\naws organizations register-delegated-administrator \\\n\u0026ndash;serviceprincipal=member.org.stacksets.cloudformation.amazonaws.com \\\n\u0026ndash;account-id=\u0026ldquo;012345678901\u0026rdquo;\nĐây là lần duy nhất chúng ta cần truy cập tài khoản quản lý. Các bước còn lại được hoàn thành từ trong tài khoản tooling.\nBootstrap AWS CDK Chọn một Region chính nơi tất cả báo cáo và sự kiện được hợp nhất trong tài khoản tooling trung tâm. Đặt biến AWS_DEFAULT_REGION thành Region chính này.\nĐối với giải pháp khám phá và báo cáo, bạn phải bootstrap AWS CDK trong Region chính này trên toàn bộ Organization. Hơn nữa, AWS CDK cũng phải được bootstrap trong tất cả các AWS Regions nơi các cluster EKS được triển khai để nhận thông báo kết thúc hỗ trợ. Để đơn giản hóa hướng dẫn này, chúng tôi chỉ demo triển khai tài nguyên đến Region chính mà bạn đã chọn.\nCác bước để bootstrap AWS CDK trên nhiều AWS Regions và tài khoản có sẵn trong bài viết này: Bootstrapping multiple AWS accounts for AWS CDK using CloudFormation StackSets.\nTải xuống các AWS CDK stacks Chúng tôi cung cấp các AWS CDK stacks để bạn nhanh chóng triển khai giải pháp trong môi trường của mình. Tải mã từ our GitHub repository và thiết lập môi trường bằng cách chạy các lệnh sau trong thư mục cdk:\npython3 -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\nHướng dẫn chi tiết Các bước sau sẽ hướng dẫn bạn qua các giải pháp này.\nGiải pháp 1: Thông báo kết thúc hỗ trợ cluster EKS Giải pháp đầu tiên của chúng tôi giải quyết nhu cầu quan trọng về nhận thức kịp thời về các sự kiện vòng đời cluster EKS, đặc biệt là việc tiếp cận ngày kết thúc hỗ trợ tiêu chuẩn. Việc sử dụng AWS Health, EventBridge và Amazon SNS (và tùy chọn Amazon SQS) cho phép chúng tôi tạo một hệ thống tập trung:\nGiám sát các sự kiện AWS Health trên nhiều AWS Regions và tài khoản Tập trung vào các sự kiện cụ thể của Amazon EKS, đặc biệt là AWS_EKS_PLANNED_LIFECYCLE_EVENT Cung cấp thông báo sớm khi một cluster EKS còn 180 ngày nữa sẽ đạt đến cuối giai đoạn hỗ trợ tiêu chuẩn và hỗ trợ mở rộng Cách tiếp cận tập trung này đảm bảo rằng người dùng Amazon EKS nhận được đủ thời gian để lập kế hoạch và thực hiện nâng cấp phiên bản, duy trì tính bảo mật và ổn định của môi trường Kubernetes của họ, như được hiển thị trong hình sau.\nHình 1: Tổng quan giải pháp – thông báo kết thúc hỗ trợ\nBước 1: Triển khai AWS CDK stack eks-health-events Triển khai AWS CDK stack eks-health-events vào tài khoản tooling trung tâm bằng lệnh sau:\ncdk deploy eks-health-events \u0026ndash;app \u0026ldquo;python3 tooling_account.py\u0026rdquo; —require-approval never\nĐiều này triển khai AWS CDK app trong tooling_account.py, cung cấp các tài nguyên sau trong tài khoản tooling trung tâm:\nEvent bus SNS topic và SQS queue để giám sát các sự kiện EventBridge rule để chuyển tiếp các sự kiện vòng đời đã lên kế hoạch cho Amazon EKS đến Amazon SNS EventBridge rule để chuyển tiếp giám sát các sự kiện vòng đời đã lên kế hoạch cho Amazon EKS đến Amazon SQS Resource policies cho các event rules để publish đến Amazon SNS và Amazon SQS Bước 2: Triển khai AWS CDK stack eks-health-events-stack-set Triển khai AWS CDK stack eks-health-events-stack-set.\ncdk deploy eks-health-events-stack-set \u0026ndash;app \u0026ldquo;python stack_sets.py\u0026rdquo; —require-approval never\nĐiều này sử dụng CloudFormation StackSets để triển khai các tài nguyên sau vào Region chính đã chọn trên tất cả các tài khoản trong Organization ngoại trừ tài khoản Management:\nLocal event bus EventBridge rule để chuyển tiếp các sự kiện vòng đời đã lên kế hoạch cho Amazon EKS đến central event bus được cung cấp trong Bước 2 Resource policies cho các event rules để publish đến central event bus Bước 3: Cấu hình thông báo SNS Duyệt đến dịch vụ Amazon SNS có tên eks-health-events-EKSHealthEvents- và tạo một subscription cho topic mới được tạo (ví dụ: địa chỉ email nhóm).\nBước 4: Xác thực giải pháp Bạn có thể kiểm tra và xác thực rằng các EventBridge rules, SQS queue và SNS topic đã được tạo bởi các CloudFormation stacks có tên eks-health-events và eks-health-events-stack-set. Từ thời điểm này trở đi, khi các cluster EKS của bạn còn 180 ngày nữa sẽ đạt đến cuối hỗ trợ (tiêu chuẩn và mở rộng), các EventBridge rules sẽ áp dụng và Amazon SNS và/hoặc Amazon SQS được kích hoạt, như được hiển thị trong các hình sau.\nHình 2: Xác thực triển khai EventBridge\nHình 3: Xác thực triển khai SQS\nHình 4: Xác thực triển khai SNS\nHình 5: Mẫu thông báo kết thúc hỗ trợ\nGiải pháp 2: Khám phá và báo cáo cluster EKS Bổ sung cho giải pháp thông báo kết thúc hỗ trợ cluster EKS, giải pháp thứ hai của chúng tôi cung cấp cái nhìn toàn diện về các cluster EKS trên toàn bộ Organization. Giải pháp này:\nXác định các cluster EKS trong tất cả các AWS Regions và tài khoản trong một Organization Thu thập thông tin chi tiết về từng cluster, chẳng hạn như chi tiết tài khoản, region, tên cluster, phiên bản và các tags liên quan Tổng hợp dữ liệu về các phiên bản cluster, cung cấp thông tin chi tiết về phân phối phiên bản Tạo cả báo cáo chi tiết và tóm tắt, được lưu trữ tập trung để truy cập trực tiếp Việc cung cấp khả năng hiển thị trên toàn tổ chức này cho phép giải pháp giúp các nhóm duy trì bảng kiểm kê chính xác về tài nguyên Amazon EKS, tạo điều kiện thuận lợi cho việc kiểm tra tuân thủ và hỗ trợ lập kế hoạch nâng cấp chiến lược, như được hiển thị trong hình sau.\nHình 6: Tổng quan giải pháp – khám phá và báo cáo\nBước 1: Triển khai AWS CDK stack eks-discovery Triển khai AWS CDK stack eks-discovery-lambda vào tài khoản tooling trung tâm bằng lệnh sau:\ncdk deploy eks-discovery-lambda —require-approval never\nĐiều này triển khai AWS CDK stack có tên eks-discovery-lambda trong tooling_account.py, cung cấp các tài nguyên sau trong tài khoản tooling trung tâm:\nLambda function để khám phá các cluster EKS trên tất cả các AWS Regions và tài khoản S3 bucket để lưu trữ kết quả SNS topic cho thông báo EventBridge scheduler để thực thi định kỳ Các IAM roles và policies cần thiết Lambda function thu thập chi tiết cluster, tạo báo cáo và gửi thông báo.\nBước 2: Sửa đổi EventBridge scheduler theo nhu cầu Nếu bạn muốn tùy chỉnh lịch khám phá cluster EKS, hãy điều hướng đến EventBridge và trong phần schedules tìm EKSDiscoveryWeeklySchedule mới được tạo. Đây là một scheduler dựa trên cron, như được hiển thị trong hình sau.\nHình 7: Tùy chỉnh lịch cho khám phá cluster\nĐể nhận thông báo từ Amazon SNS, bạn phải tạo một subscription cho topic. Để làm điều này, hãy điều hướng đến dịch vụ Amazon SNS, tìm Topic mới được tạo có tên EKSDiscoverySNSTopic và cấu hình giao thức để đáp ứng yêu cầu của bạn (ví dụ: gửi email đến một nhóm).\nBước 3: Triển khai cross-account role mà Lambda function có thể assume để thực hiện khám phá Lambda function bạn triển khai trong Bước 1 dựa vào một cross-account role trong mỗi tài khoản trong Organization để thực hiện khám phá cluster.\nTriển khai AWS CDK stack eks-discovery-stack-set để triển khai cross-account role này.\ncdk deploy eks-discovery-stack-set \u0026ndash;app \u0026ldquo;python stack_sets.py\u0026rdquo; \u0026ndash;require-approval never\nBước 4: Xác thực giải pháp Để xác thực giải pháp, hãy điều hướng đến Lambda function mới được tạo và test với một event mới và một đối tượng JSON rỗng. Khi Lambda hoàn thành, hãy xác minh rằng S3 bucket nhận được file zip và xác nhận rằng bạn đã nhận được thông báo SNS, như được hiển thị trong các hình sau.\nHình 8: Mẫu output khám phá cluster trong S3 bucket\nHình 9: Mẫu nội dung của output file\nHình 10: Mẫu danh sách clusters\nHình 11: Mẫu số lượng clusters theo phiên bản\nBước 5: (Tùy chọn) Giám sát giải pháp Bạn có thể muốn giám sát giải pháp. Điều này có thể được thực hiện bằng cách thiết lập Amazon CloudWatch Alarms để giám sát việc thực thi của Lambda function và bất kỳ lỗi tiềm ẩn nào. Hơn nữa, hãy thường xuyên xem xét các báo cáo được tạo trong S3 bucket và định kỳ xem xét và cập nhật các quyền IAM nếu cần.\nKhắc phục sự cố Đảm bảo rằng tất cả các IAM roles và policies được thiết lập chính xác và có các quyền cần thiết. Kiểm tra CloudWatch Logs để tìm bất kỳ thông báo lỗi nào trong các Lambda functions hoặc EventBridge rules. Cân nhắc về bảo mật Xem xét và điều chỉnh các IAM roles và policies để tuân thủ nguyên tắc đặc quyền tối thiểu và môi trường của bạn. Thường xuyên kiểm toán quyền truy cập vào hệ thống quản lý sự kiện tập trung. Dọn dẹp Chạy các lệnh sau để dọn dẹp các tài nguyên đã cung cấp:\ncdk destroy \u0026ndash;app \u0026ldquo;python stack_sets.py\u0026rdquo; \u0026ndash;all \u0026ndash;force\ncdk destroy \u0026ndash;all \u0026ndash;force\nLệnh đầu tiên xóa các CloudFormation StackSets đã được triển khai trên toàn bộ Organization bằng AWS CDK App có tên stack_sets.py.\nLệnh thứ hai dọn dẹp các tài nguyên được cung cấp trong tài khoản tooling trung tâm bằng AWS CDK App có tên tooling_account.py.\nKết luận Hướng dẫn này có thể giúp bạn thiết lập một hệ thống mạnh mẽ sử dụng các dịch vụ AWS để cung cấp thông báo chủ động về kết thúc hỗ trợ tiêu chuẩn. Điều này cho phép lập kế hoạch kịp thời cho các nâng cấp, giảm thiểu rủi ro từ các cluster lỗi thời trong khi duy trì tính bảo mật, ổn định và tuân thủ. Hơn nữa, giải pháp khám phá và báo cáo cluster Amazon EKS đánh dấu một bước tiến đáng kể trong việc quản lý các môi trường Kubernetes đa tài khoản phức tạp trên AWS. Giải pháp tăng cường khả năng hiển thị, hợp lý hóa nỗ lực tuân thủ, tạo điều kiện thuận lợi cho việc lập kế hoạch chiến lược và hỗ trợ ra quyết định sáng suốt cho việc nâng cấp cluster và phân bổ tài nguyên.\nKhi các tổ chức tiếp tục mở rộng quy mô ứng dụng container hóa của họ, các giải pháp này trở thành tài sản vô giá. Chúng cho phép các nhóm duy trì cái nhìn tổng quan rõ ràng về cảnh quan Amazon EKS của họ, tối ưu hóa việc sử dụng tài nguyên và đảm bảo các thực hành quản lý nhất quán trên các triển khai đa dạng. Việc triển khai các giải pháp này cho phép bạn thực hiện một bước tiến đáng kể trong việc quản lý khả năng quan sát, khả năng phục hồi và quản trị của các môi trường Amazon EKS của bạn. Đến lượt nó, điều này đảm bảo thành công lâu dài và khả năng mở rộng của các sáng kiến Kubernetes của bạn trên AWS.\nChúng tôi khuyến nghị thử cả hai giải pháp để bắt đầu tăng cường khả năng quan sát cluster EKS của bạn ngay hôm nay!\nNguồn gốc: AWS Containers Blog Ngày xuất bản: 12 tháng 3, 2025 Danh mục: Amazon EKS, AWS Health, Container Management, Kubernetes\n"},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/1-worklog/1.3-week3/","title":"Nhật ký Tuần 3","tags":[],"description":"","content":"Mục tiêu Tuần 3: Hiểu sâu hơn về kiểm soát truy cập với AWS IAM: User, Group, Policy, Role. Biết cách thiết kế mô hình phân quyền an toàn dựa trên IAM Role và nguyên tắc “least privilege”. Thực hành tạo IAM Group, IAM User, IAM Role và kịch bản Switch Role. Nắm các khái niệm mạng cơ bản trong Amazon VPC: Subnet, Route Table, Internet Gateway, NAT Gateway. Thực hành xây dựng VPC, cấu hình Security Group, Network ACL và làm quen với Site-to-Site VPN. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Tìm hiểu tổng quan về IAM Access Control + IAM User \u0026amp; IAM Group + IAM Policy + IAM Role - Ôn lại mục tiêu bảo mật và nguyên tắc least privilege 09/23/2025 09/23/2025 https://000002.awsstudygroup.com/ 2 - Thực hành IAM (1): + Tạo Admin IAM Group + Tạo Admin User và thêm vào group + Đăng nhập bằng Admin User và kiểm tra quyền 09/24/2025 09/24/2025 https://000002.awsstudygroup.com/ 3 - Thực hành IAM (2): + Tạo Admin Role + Tạo OperatorUser + Cấu hình trust relationship cho Switch Role + Test Switch Role từ OperatorUser + Rà soát \u0026amp; dọn dẹp cấu hình không cần thiết 09/25/2025 09/25/2025 https://000002.awsstudygroup.com/ 4 - Học lý thuyết về Amazon VPC: + Subnet + Route Table + Internet Gateway + NAT Gateway - So sánh và hiểu vai trò: + Security Group + Network ACL 09/26/2025 09/26/2025 https://000003.awsstudygroup.com/ 5 - Thực hành VPC \u0026amp; Networking: + Tạo VPC, Subnet, Internet Gateway, Route Table, Security Group + Bật VPC Flow Logs + Tạo EC2 trong VPC và test kết nối + Đọc và hiểu các bước cấu hình Site-to-Site VPN 09/27/2025 09/27/2025 https://000003.awsstudygroup.com/ Thành tựu Tuần 3: Hiểu rõ hơn về các thành phần IAM trong kiểm soát truy cập:\nIAM User, IAM Group IAM Policy và cách gán quyền IAM Role và trust relationship Xây dựng được cấu trúc IAM cơ bản cho quản trị:\nTạo Admin Group, Admin User Kiểm tra quyền dựa trên group thay vì gán trực tiếp Thực hành mô hình phân quyền nâng cao:\nTạo Admin Role và OperatorUser Cấu hình và test Switch Role trong Console Áp dụng nguyên tắc least privilege khi phân quyền Nắm được các khái niệm chính của Amazon VPC:\nSubnet, Route Table, Internet Gateway, NAT Gateway Phân biệt Security Group và Network ACL Tự tay xây dựng một môi trường VPC nhỏ:\nTạo VPC, subnet, routing, lớp bảo mật Khởi tạo EC2 trong VPC và kiểm tra kết nối Bật VPC Flow Logs để quan sát traffic Nắm được luồng tổng quát để thiết lập AWS Site-to-Site VPN cho môi trường hybrid.\n"},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/5-workshop/5.3-bedrock-models/","title":"Kích hoạt Bedrock Models","tags":[],"description":"","content":"Trước khi triển khai giải pháp, bạn cần kích hoạt các mô hình Amazon Bedrock cần thiết trong tài khoản AWS của mình.\nCác bước Kích hoạt Mô hình Tìm kiếm Amazon Bedrock trong AWS Console Truy cập Model catalog từ menu điều hướng bên trái Chọn tên mô hình tương ứng: Anthropic Claude 3.5 Sonnet Anthropic Claude 3 Sonnet Anthropic Claude 3 Haiku Cohere - Embed Multilingual v3 Chọn \u0026ldquo;Open in playground\u0026rdquo; và gửi một tin nhắn thử nghiệm để kích hoạt từng mô hình Lưu ý: Đảm bảo bạn kích hoạt tất cả bốn mô hình trong khu vực ap-southeast-1 (Singapore) vì giải pháp được triển khai trong khu vực này.\n"},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Báo cáo tóm tắt: \u0026ldquo;AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS\u0026rdquo; Mục đích của Workshop Cung cấp cái nhìn tổng quan về hệ sinh thái AI/ML/GenAI trên AWS, tập trung vào các dịch vụ quan trọng nhất. Trang bị cho người tham dự kiến thức thực tiễn về quy trình AI/ML – từ chuẩn bị dữ liệu đến huấn luyện và triển khai mô hình với Amazon SageMaker. Giới thiệu ứng dụng Generative AI với Amazon Bedrock, bao gồm prompt engineering, RAG và xây dựng automation agents. Tạo môi trường để sinh viên và lập trình viên kết nối và trao đổi kinh nghiệm AI/ML thực tế trên nền tảng đám mây. Diễn giả / Giảng viên (Theo chương trình workshop) Nguyễn Gia Hưng – Head of Solutions Architect, AWS Vietnam Trần Thị Minh Anh – Senior AI/ML Specialist Solutions Architect, AWS Lê Quang Huy – Cloud Engineer \u0026amp; AI Enthusiast Nội dung \u0026amp; Kiến thức chính 1. Tổng quan hệ sinh thái AWS AI/ML/GenAI Bối cảnh Việt Nam: Việc ứng dụng AI đang tăng trưởng rất nhanh; nhu cầu về kỹ sư AI/ML và kỹ sư am hiểu cloud tiếp tục gia tăng. Lộ trình học tập: Từ các khóa nền tảng đến chứng chỉ nâng cao, nhấn mạnh thực hành hands-on. Ba nhóm dịch vụ: AI Services (dùng ngay), ML Services (tùy biến), và Generative AI (mở ra nhiều khả năng mới). 2. Amazon SageMaker – Nền tảng ML toàn diện Hỗ trợ toàn bộ vòng đời ML trên một nền tảng duy nhất. SageMaker Studio cung cấp môi trường phát triển tích hợp, giúp tăng tốc quá trình xây dựng mô hình. Cho phép thực hiện MLOps, tự động hóa huấn luyện, tinh chỉnh siêu tham số (hyperparameter tuning) và triển khai mô hình. 3. Generative AI với Amazon Bedrock Cung cấp nhiều Foundation Model như Claude, Llama và Titan cho các tác vụ khác nhau. Advanced Prompt Engineering: sử dụng Chain-of-Thought, few-shot để cải thiện chất lượng đầu ra. RAG (Retrieval-Augmented Generation): kết hợp LLM với dữ liệu riêng tư để giảm hallucination và mở rộng phạm vi kiến thức. Bedrock Agents: giúp mô hình thực hiện các tác vụ nhiều bước và tương tác với hệ thống bên ngoài. Guardrails: đảm bảo nội dung an toàn và tuân thủ. Những điều rút ra chính Góc nhìn công nghệ SageMaker không chỉ là công cụ huấn luyện mà là một nền tảng quản lý toàn bộ vòng đời ML. Generative AI hiệu quả phụ thuộc vào sự kết hợp giữa mô hình, kỹ thuật prompt và các kiến trúc hỗ trợ như RAG. Dữ liệu vẫn là yếu tố quan trọng nhất quyết định chất lượng mô hình. Tư duy \u0026amp; Phương pháp Bắt đầu từ bài toán thực tế thay vì chạy theo xu hướng công nghệ. Áp dụng cách tiếp cận lặp (iterative): xây dựng nhanh → lấy phản hồi → cải tiến. Luôn đánh giá chi phí để đảm bảo tính khả thi của dự án. Kỹ năng thực hành Prompt engineering cần được luyện tập liên tục. Thành thạo AWS Console/SDK là điều thiết yếu để xây dựng sản phẩm AI thực tế. Kế hoạch hành động cá nhân sau Workshop Thực hành với AWS Free Tier — bắt đầu với SageMaker Studio Lab để khám phá các workflow ML. Xây dựng ứng dụng GenAI đầu tiên — ví dụ: tạo một chatbot đơn giản sử dụng Amazon Bedrock. Đào sâu kiến thức qua AWS Skill Builder — hoàn thành các lộ trình học về ML và Generative AI. Tham gia cộng đồng AI/ML tại Việt Nam để luôn cập nhật case study và kinh nghiệm thực hành. Trải nghiệm cá nhân tại sự kiện Workshop “AI/ML/GenAI on AWS” đã mang lại một góc nhìn rõ ràng và thực tế hơn về cách tiếp cận AI theo định hướng chuyên nghiệp. Môi trường văn phòng hiện đại của AWS, sự nhiệt tình của các diễn giả và cách truyền đạt dễ hiểu khiến nội dung trở nên rất cuốn hút.\nPhần demo trực tiếp là ấn tượng nhất. Khi thấy chị Minh Anh xây dựng một hệ thống RAG và Bedrock Agent chạy được trong thời gian ngắn, mình nhận ra việc prototyping AI đã trở nên “dễ thở” hơn rất nhiều khi dùng đúng công cụ.\nNhững chia sẻ về quản lý chi phí và MLOps đặc biệt hữu ích — chúng giúp mình hiểu rằng làm AI không chỉ là xây xong một mô hình, mà còn là quản lý, giám sát và tối ưu nó liên tục.\nSau workshop, mình cảm thấy tự tin hơn khi theo đuổi AI/ML trên AWS, vì giờ đây mình đã có một lộ trình rõ ràng và thực tiễn hơn để đi tiếp.\n"},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Báo cáo tóm tắt: \u0026ldquo;AWS Cloud Mastery Series #2: DevOps on AWS\u0026rdquo; Mục đích của Workshop Cung cấp cái nhìn tổng quan toàn diện về văn hóa, nguyên tắc và thực hành DevOps trên AWS. Minh họa cách xây dựng một pipeline CI/CD hoàn chỉnh — từ quản lý mã nguồn đến triển khai tự động. Giới thiệu các công cụ Infrastructure as Code (IaC) chính trên AWS và cách ứng dụng thực tế. Trang bị cho người tham dự kiến thức về containerization, observability và các thực hành vận hành tốt nhất. Diễn giả / Giảng viên chính (Dự kiến) Đỗ Huy Thắng – DevOps Lead, VNG Nguyễn Thị Thu Hà – Senior DevOps Engineer, AWS Phạm Tuấn Anh – Solutions Architect, AWS Các chủ đề \u0026amp; nội dung học chính 1. Văn hóa DevOps \u0026amp; Các nguyên tắc cốt lõi DevOps không chỉ là công cụ — đó là một văn hóa hợp tác giữa Development và Operations. Các chỉ số DORA (Tần suất triển khai, Thời gian đưa thay đổi vào sản xuất, MTTR, Tỷ lệ thay đổi lỗi) là những chỉ báo quan trọng về hiệu quả DevOps. Shift-left Testing \u0026amp; Security giúp phát hiện vấn đề sớm hơn và giảm chi phí khắc phục. 2. CI/CD Pipeline trên AWS AWS DevTools (CodeCommit, CodeBuild, CodeDeploy, CodePipeline) cho phép xây dựng quy trình phát hành tự động hoàn toàn. Các chiến lược triển khai gồm Blue/Green, Canary và Rolling Updates. Demo trực tiếp: commit → build → test → deploy lên EC2/ECS. 3. Infrastructure as Code (IaC) AWS CloudFormation: IaC theo kiểu khai báo bằng template YAML/JSON. AWS CDK: IaC theo kiểu lập trình (imperative) dùng các ngôn ngữ như Python hoặc TypeScript, hỗ trợ tái sử dụng mạnh. Drift Detection giúp đảm bảo hạ tầng luôn nhất quán với cấu hình đã định nghĩa. 4. Containers \u0026amp; Microservices Docker đóng gói ứng dụng thành các container nhẹ, di động, tách biệt. So sánh Amazon ECS và Amazon EKS để lựa chọn công cụ điều phối phù hợp. AWS App Runner cung cấp triển khai container dạng serverless với chi phí vận hành tối thiểu. 5. Monitoring \u0026amp; Observability Amazon CloudWatch: metrics, logs, alarms, dashboards để theo dõi sức khỏe hệ thống theo thời gian thực. AWS X-Ray: distributed tracing để phân tích hiệu năng và xác định các nút thắt độ trễ. Thực hành tốt bao gồm cảnh báo có ý nghĩa, dashboard gắn với SLO, và quy trình postmortem có cấu trúc. Những điều rút ra chính Tư duy \u0026amp; Văn hóa DevOps là một hành trình cải tiến liên tục. Tự động hóa là xương sống của DevOps. Áp dụng tư duy “blameless postmortem” để học từ thất bại. Kiến thức kỹ thuật CI/CD là xây dựng một quy trình phân phối đáng tin cậy, không chỉ là chạy script. IaC mang lại tính nhất quán, khả năng quản lý phiên bản và tái tạo môi trường. Observability cung cấp góc nhìn sâu hơn để phân tích nguyên nhân gốc rễ. Kỹ năng nghề nghiệp Kỹ sư DevOps cần nền tảng rộng: networking, security, coding, vận hành hệ thống. Kỹ năng debug nâng cao là thiết yếu trong môi trường hệ thống phân tán. Kế hoạch hành động cá nhân Xây dựng một CI/CD pipeline cá nhân dùng CodeCommit \u0026amp; CodePipeline. Thực hành AWS CDK với Python để triển khai các tài nguyên AWS cốt lõi. Đóng gói một ứng dụng nhỏ bằng Docker và deploy trên ECS Fargate. Tạo một CloudWatch dashboard với các metrics và alarms quan trọng. Cảm nhận cá nhân Workshop mang lại nhiều góc nhìn thực tế mà lập trình viên thường dễ bỏ qua.\nPhần demo CI/CD và IaC đặc biệt ấn tượng, cho thấy tự động hóa giúp giảm rủi ro và tăng tốc vòng đời phát hành như thế nào.\nCác case study thực tế từ VNG và AWS nhấn mạnh vai trò then chốt của monitoring và văn hóa DevOps.\n"},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":" Trong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 6 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEVENt 1 Tên sự kiện: Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders\nThời gian: 09:00 - 17:00 , ngày 18/9/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: AI-Driven Development Life Cycle: Reimagining Software\nThời gian: 14:00 - 16:30, ngày 3/10/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS\nThời gian: 8:00 - 11:3, ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 4 Tên sự kiện: AWS Cloud Mastery Series #2\nThời gian: 8:30 - 17:00, ngày 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 5 Tên sự kiện: AWS Cloud Mastery Series #3\nThời gian: 8:30 - 12:00, ngày 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 6 Tên sự kiện: Next Step: Create Your Workspace \u0026amp; Connect Your Cloud\nThời gian: 8:30 - 12:00, ngày 6/12/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Báo cáo tóm tắt: Buổi sinh hoạt CLB – \u0026ldquo;AI-Driven Development Life Cycle: Reimagining Software Engineering\u0026rdquo; Mục đích của buổi sinh hoạt Khám phá cách Generative AI đang thay đổi diện mạo phát triển phần mềm hiện đại. Hiểu cách tích hợp AI vào toàn bộ vòng đời phát triển phần mềm (SDLC), từ kiến trúc đến bảo trì. Trải nghiệm thực tế các công cụ phát triển được hỗ trợ bởi AI như Amazon Q Developer và Kiro. Diễn giả \u0026amp; Ban tổ chức Người dẫn chính: Toan Huynh – Trình bày về AI-Driven SDLC và demo Amazon Q Developer My Nguyen – Demo Kiro Điều phối: Diem My, Dai Truong, Dinh Nguyen (AWS GenAI Builder Club Vietnam) Nội dung \u0026amp; Kiến thức chính 1. Tổng quan về vòng đời phát triển phần mềm được dẫn dắt bởi AI Generative AI đang tái định hình toàn bộ SDLC (vòng đời phát triển phần mềm), chứ không chỉ hỗ trợ các tác vụ nhỏ lẻ. AI tự động hóa các công việc lặp lại như viết mã khung (boilerplate), tạo test case và debug cơ bản. Lập trình viên đang chuyển từ việc tự viết từng dòng code sang thiết kế, giám sát và cộng tác với AI. 2. Amazon Q Developer – Trợ lý AI cho lập trình viên từ đầu đến cuối Hỗ trợ tất cả các giai đoạn của SDLC: lập kế hoạch, phân tích yêu cầu, thiết kế kiến trúc lập trình, giải thích code, refactor, chuyển đổi ngôn ngữ debug và kiểm thử hướng dẫn triển khai và xử lý sự cố Tích hợp sâu với AWS, tăng năng suất cho các workload cloud-native. Được xây dựng với nguyên tắc bảo mật mạnh mẽ – dữ liệu doanh nghiệp không được dùng để huấn luyện mô hình toàn cục. 3. Kiro – Pair Programming với AI trong thực tế Hiểu các codebase phức tạp và đưa ra đề xuất chỉnh sửa thông minh. Tăng tốc phát triển bằng cách tạo ra code chính xác, sẵn sàng cho môi trường production. Đóng vai trò “người bạn học tập”, giúp khám phá nhanh các ngôn ngữ hoặc framework mới. Những điều rút ra chính Xu hướng \u0026amp; Định hướng tương lai AI sẽ không thay thế lập trình viên; thay vào đó, AI nâng tầm vai trò của họ lên các nhiệm vụ giải quyết vấn đề, thiết kế hệ thống và đảm bảo chất lượng. Tốc độ sẽ trở thành lợi thế cạnh tranh cho những tổ chức áp dụng AI xuyên suốt SDLC. Kỹ năng cần phát triển Prompt engineering trở nên thiết yếu: diễn đạt yêu cầu rõ ràng và kiểm chứng kết quả AI sinh ra. Cần tư duy kiến trúc và kỹ năng giám sát để đánh giá code do AI tạo ra một cách an toàn. Nền tảng kỹ thuật vẫn cực kỳ quan trọng: giải thuật, cấu trúc dữ liệu và thiết kế hệ thống giúp lập trình viên “dẫn dắt” AI hiệu quả hơn. Kế hoạch hành động cá nhân Đăng ký và sử dụng Amazon Q Developer trong VSCode/JetBrains cho các tác vụ hằng ngày. Luyện tập prompt engineering cho các ngữ cảnh lập trình – sinh code, viết test, debug. Chủ động tham gia cộng đồng AWS GenAI Builder Club. Áp dụng quy trình phát triển được dẫn dắt bởi AI cho một module thực tế trong dự án cá nhân hoặc dự án nhóm. Cảm nhận cá nhân Buổi sinh hoạt câu lạc bộ này giống như được chứng kiến bước tiến tiếp theo của ngành kỹ nghệ phần mềm.\nViệc thấy Amazon Q Developer và Kiro hoạt động trực tiếp – đề xuất cải tiến, phát hiện lỗ hổng tiềm ẩn và chuyển đổi prompt ngôn ngữ tự nhiên thành code chạy được – thực sự rất ấn tượng.\nThông điệp tác động nhất là: “AI là công cụ trao quyền, không phải thay thế.”\nNhững lập trình viên biết cách cộng tác với AI sẽ có lợi thế rất lớn trong tương lai.\nBuổi chia sẻ này cũng truyền cảm hứng để mình chủ động chinh phục các công cụ AI và tích hợp chúng vào quy trình làm việc, như một phần không thể thiếu trên hành trình trở thành lập trình viên thế hệ mới.\n"},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/1-worklog/1.4-week4/","title":"Nhật ký Tuần 4","tags":[],"description":"","content":"Mục tiêu Tuần 4: Hiểu cách khởi tạo và quản lý EC2 Windows và Linux. Thực hành triển khai ứng dụng trên EC2 (Node.js \u0026amp; AWS User Management App). Hiểu IAM governance và quản lý chi phí EC2 thông qua IAM. Hiểu cách ứng dụng truy cập dịch vụ AWS qua IAM Role thay cho Access Key. Thực hành gán IAM Role cho EC2 và kiểm tra quyền truy cập của ứng dụng. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Tìm hiểu giới thiệu EC2 \u0026amp; bước chuẩn bị + Khái niệm EC2 + Các tài nguyên cần thiết + Yêu cầu IAM \u0026amp; networking 09/30/2025 09/30/2025 https://000004.awsstudygroup.com/ 2 - Khởi tạo EC2: + Tạo Windows Server 2022 instance + Tạo Amazon Linux instance + Kết nối và kiểm tra truy cập 10/01/2025 10/01/2025 https://000004.awsstudygroup.com/ 3 - Triển khai ứng dụng: + Triển khai AWS User Management App trên Amazon Linux 2 + Triển khai Node.js App trên Windows EC2 10/02/2025 10/02/2025 https://000004.awsstudygroup.com/ 4 - IAM Governance \u0026amp; Authorization: + Hiểu governance chi phí \u0026amp; sử dụng với IAM + So sánh Access Key vs IAM Role + Rủi ro của việc dùng Access Key lâu dài 10/03/2025 10/03/2025 https://000048.awsstudygroup.com/ 5 - Thực hành IAM Role cho EC2: + Tạo IAM Role cho EC2 + Gán Role vào EC2 instance + Kiểm tra ứng dụng truy cập AWS qua Role + Clean up resource sau bài học 10/04/2025 10/04/2025 https://000048.awsstudygroup.com/ Thành tựu Tuần 4: Khởi tạo thành công EC2 Windows và Linux. Hiểu cách chuẩn bị môi trường EC2 để triển khai ứng dụng. Triển khai thành công 2 ứng dụng: AWS User Management App (Linux) Node.js App (Windows) Hiểu rõ IAM governance \u0026amp; ảnh hưởng của IAM tới chi phí và bảo mật. Nắm được lý do không nên dùng Access Key cho ứng dụng. Tạo và gán IAM Role cho EC2, giúp ứng dụng truy cập AWS service an toàn. Kiểm tra thành công quyền truy cập dựa trên IAM Role. Dọn dẹp tài nguyên để tránh phát sinh chi phí. "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/5-workshop/5.4-aws-cli/","title":"Cấu hình AWS CLI","tags":[],"description":"","content":"Cấu hình AWS CLI Để triển khai và quản lý giải pháp, bạn cần cấu hình AWS Command Line Interface (AWS CLI) với thông tin xác thực của mình.\nCác bước Bước 1: Kiểm tra AWS CLI đã cài đặt aws --version Nếu chưa có, cài đặt:\n# Download và cài đặt MSI installer msiexec.exe /i https://awscli.amazonaws.com/AWSCLIV2.msi Bước 2: Tạo IAM User (nếu chưa có) Đăng nhập AWS Console Tìm kiếm \u0026ldquo;IAM\u0026rdquo; → Click IAM Sidebar trái → Users → Create user User name: arc-workshop-user Click Next Attach policies directly, chọn các policies: AmazonEC2FullAccess AmazonS3FullAccess AmazonDynamoDBFullAccess AmazonCognitoPowerUser AmazonSQSFullAccess AmazonTextractFullAccess AmazonBedrockFullAccess CloudWatchFullAccess IAMFullAccess Click Create user Bước 3: Tạo Access Key Vào user vừa tạo → Tab Security credentials Scroll xuống Access keys → Click Create access key Chọn Command Line Interface (CLI) Tick \u0026ldquo;I understand\u0026hellip;\u0026rdquo; → Next Description: ARC Workshop CLI Click Create access key ⚠️ QUAN TRỌNG: Copy hoặc download .csv file\nAccess key ID: AKIAXXXXXXXXXXXXXXXX Secret access key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Bước 4: Configure AWS CLI Mở PowerShell và chạy:\naws configure Nhập thông tin:\nAWS Access Key ID [None]: AKIAXXXXXXXXXXXXXXXX AWS Secret Access Key [None]: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Default region name [None]: ap-southeast-1 Default output format [None]: json Bước 5: Verify Configuration Kiểm tra identity:\naws sts get-caller-identity Output mong đợi:\n{ \u0026#34;UserId\u0026#34;: \u0026#34;AIDAXXXXXXXXXXXXXXXXX\u0026#34;, \u0026#34;Account\u0026#34;: \u0026#34;123456789012\u0026#34;, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:iam::123456789012:user/arc-workshop-user\u0026#34; } "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"Bước tiếp theo: Tạo Workspace \u0026amp; Kết nối Cloud của bạn Workspace của bạn sẽ là trung tâm điều khiển, nơi bạn có thể:\nKết nối các tài khoản cloud Theo dõi chi tiêu Nhận các gợi ý tiết kiệm chi phí được hỗ trợ bởi AI "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Tìm hiểu các thành phần chính của EC2 và cách vận hành compute trong AWS. Nắm cơ chế Auto Scaling, EBS, Instance Store, User Data, Metadata. Thực hành backup, Storage Gateway và triển khai EC2 phục vụ cho lưu trữ. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về EC2, các loại instance, AMI, key pair - Biết được EBS, Instance Store, User Data, Metadata 06/10/2025 06/10/2025 https://youtu.be/-t5h4N6vfBs?si=GeVdhO9IEDjzzS_D https://youtu.be/e7XeKdOVq40?si=T3I4pgPoEfVytcU3 https://youtu.be/yAR6QRT3N1k?si=GQghyBwLCpijrDON https://youtu.be/hKr_TfGP7NY?si=gR2MqaLAFrqL-KBo https://youtu.be/6IHNDJ85aoQ?si=M0puk6DJpliO7ahf https://youtu.be/_v_43Wi7zjo?si=qNDVWzKcQFNO2mGh https://youtu.be/Ew3QRaKJQSA?si=xNvXvD8yFhnSMJby 3 - Nắm bắt được EC2 Auto Scaling và cách scale VM - tìm hiểu về các dịch vụ lưu trữ và compute (EFS/FSx, Lightsail, MGN overview) 07/10/2025 07/10/2025 https://youtu.be/bbLcPitXJSY?si=eyVnxvL9ho0LpUYy https://youtu.be/hFVYG8WqfU0?si=9Px4wmR4IRZxk15n 4 - Thực hành: + Deploy AWS Backup + Create backup plan + Test restore \u0026amp; cleanup + Dọn dẹp backup 08/10/2025 08/10/2025 https://000013.awsstudygroup.com 5 - Thực hành: + Create S3 bucket để làm Storage Gateway + Create EC2 cho Storage Gateway + Create Storage Gateway + File Share + Dọn dẹp Storage Gateway 09/10/2025 09/10/20255 https://000024.awsstudygroup.com 6 - Thực hành: + Create bucket, upload dữ liệu + Enable static website hosting + Cấu hình public access block + Cấu hình CloudFront và test website + Dọn dẹp website + CloudFront + bucket 10/10/2025 10/10/2025 https://000057.awsstudygroup.com Kết quả đạt được tuần 5: Tổng quát:\nTrong tuần này tôi đã hiểu cơ chế vận hành EC2, các loại storage của instance, Auto Scaling và backup. Đồng thời làm quen Storage Gateway và triển khai S3 static website Lý thuyết đã học:\nKhái niệm về kiến trúc EC2, AMI, key pair EBS vs Instance Store User Data / Metadata EC2 Auto Scaling Storage Gateway và nền tảng về Backup Thực hành với bài lab:\nTạo backup plan + test restore Tạo Storage Gateway + file share Tạo static website bằng S3 + CloudFront "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/5-workshop/5.5-data-preparation/","title":"Chuẩn bị Dữ liệu","tags":[],"description":"","content":"Chuẩn bị Dữ liệu Trước khi tạo AWS resources, bạn cần tải xuống tập dữ liệu mẫu để test hệ thống.\nBước 1: Tải Xuống Tập Dữ liệu Truy cập ARC Sample Data Tải dữ liệu về máy tính của bạn Giải nén file, sẽ tạo ra một thư mục có tên DATA Yêu cầu Documents Limit Value Format PDF (text-based hoặc scanned) Max size 50 MB Max pages 500 pages Recommended 10-100 pages Chuẩn bị AWS Resources Bước 2: Tạo S3 Bucket S3 Bucket dùng để lưu trữ documents PDF được upload.\nTìm kiếm S3 trong AWS Console Click Create bucket Cấu hình bucket: Bucket name: arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt; (thay \u0026lt;YOUR-ACCOUNT-ID\u0026gt; bằng AWS Account ID của bạn) AWS Region: Asia Pacific (Singapore) ap-southeast-1 Giữ các settings khác mặc định Click Create bucket 💡 Tip: Để lấy AWS Account ID, chạy:\naws sts get-caller-identity --query Account --output text Hoặc tạo bằng CLI:\naws s3 mb s3://arc-documents-$(aws sts get-caller-identity --query Account --output text) --region ap-southeast-1 Bước 3: Tạo DynamoDB Table DynamoDB Table dùng để lưu metadata của documents.\nTìm kiếm DynamoDB trong AWS Console Click Create table Cấu hình table: Table name: arc-documents Partition key: doc_id (String) Sort key: sk (String) Table settings: Default settings Click Create table Hoặc tạo bằng CLI:\naws dynamodb create-table \\ --table-name arc-documents \\ --attribute-definitions \\ AttributeName=doc_id,AttributeType=S \\ AttributeName=sk,AttributeType=S \\ --key-schema \\ AttributeName=doc_id,KeyType=HASH \\ AttributeName=sk,KeyType=RANGE \\ --billing-mode PAY_PER_REQUEST \\ --region ap-southeast-1 Bước 4: Tạo SQS Queue SQS Queue dùng cho IDP pipeline xử lý documents.\nTìm kiếm SQS trong AWS Console Click Create queue Cấu hình queue: Type: Standard Name: arc-document-queue Giữ các settings khác mặc định Click Create queue Hoặc tạo bằng CLI:\naws sqs create-queue --queue-name arc-document-queue --region ap-southeast-1 Bước 5: Verify Resources Kiểm tra tất cả resources đã được tạo:\n# S3 Bucket aws s3 ls | grep arc-documents # DynamoDB Table aws dynamodb describe-table --table-name arc-documents --region ap-southeast-1 --query \u0026#34;Table.TableName\u0026#34; # SQS Queue aws sqs get-queue-url --queue-name arc-document-queue --region ap-southeast-1 Bước 6: Upload Dữ liệu lên S3 Upload các file PDF từ thư mục DATA đã tải về ở Bước 1:\n# Upload tất cả files từ thư mục DATA aws s3 cp DATA/ s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ --recursive # Hoặc upload từng file aws s3 cp DATA/sample-document.pdf s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ 💡 Tip: Thay \u0026lt;YOUR-ACCOUNT-ID\u0026gt; bằng AWS Account ID của bạn\nVerify upload:\naws s3 ls s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ Checklist Trước khi tiếp tục, đảm bảo:\nAWS CLI installed và configured Terraform installed Docker installed và running Node.js 18+ installed Python 3.11+ installed Git installed Repository cloned IAM user created với đủ permissions Bedrock models được approve (Claude + Cohere) S3 Bucket created DynamoDB Table created SQS Queue created Sample documents uploaded to S3 Cấu hình bucket: Bucket name: arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt; (thay \u0026lt;YOUR-ACCOUNT-ID\u0026gt; bằng AWS Account ID của bạn) AWS Region: Asia Pacific (Singapore) ap-southeast-1 Giữ các settings khác mặc định Click Create bucket 💡 Tip: Để lấy AWS Account ID, chạy: aws sts get-caller-identity --query Account --output text\nHoặc tạo bằng CLI:\naws s3 mb s3://arc-documents-$(aws sts get-caller-identity --query Account --output text) --region ap-southeast-1 Bước 3: Tạo DynamoDB Table DynamoDB Table dùng để lưu metadata của documents.\nTìm kiếm DynamoDB trong AWS Console Click Create table Cấu hình table: Table name: arc-documents Partition key: doc_id (String) Sort key: sk (String) Table settings: Default settings Click Create table Hoặc tạo bằng CLI:\naws dynamodb create-table \\ --table-name arc-documents \\ --attribute-definitions \\ AttributeName=doc_id,AttributeType=S \\ AttributeName=sk,AttributeType=S \\ --key-schema \\ AttributeName=doc_id,KeyType=HASH \\ AttributeName=sk,KeyType=RANGE \\ --billing-mode PAY_PER_REQUEST \\ --region ap-southeast-1 Bước 4: Tạo SQS Queue SQS Queue dùng cho IDP pipeline xử lý documents.\nTìm kiếm SQS trong AWS Console Click Create queue Cấu hình queue: Type: Standard Name: arc-document-queue Giữ các settings khác mặc định Click Create queue Hoặc tạo bằng CLI:\naws sqs create-queue --queue-name arc-document-queue --region ap-southeast-1 Bước 5: Verify Resources Kiểm tra tất cả resources đã được tạo:\n# S3 Bucket aws s3 ls | grep arc-documents # DynamoDB Table aws dynamodb describe-table --table-name arc-documents --region ap-southeast-1 --query \u0026#34;Table.TableName\u0026#34; # SQS Queue aws sqs get-queue-url --queue-name arc-document-queue --region ap-southeast-1 Bước 6: Upload Dữ liệu lên S3 Upload các file PDF từ thư mục DATA đã tải về ở Bước 1:\n# Upload tất cả files từ thư mục DATA aws s3 cp DATA/ s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ --recursive # Hoặc upload từng file aws s3 cp DATA/sample-document.pdf s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ 💡 Tip: Thay \u0026lt;YOUR-ACCOUNT-ID\u0026gt; bằng AWS Account ID của bạn\nVerify upload:\naws s3 ls s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ Checklist Trước khi tiếp tục, đảm bảo:\nAWS CLI installed và configured Terraform installed Docker installed và running Node.js 18+ installed Python 3.11+ installed Git installed Repository cloned IAM user created với đủ permissions Bedrock models được approve (Claude + Cohere) Sample documents sẵn sàng "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Tổng quan Trong workshop này, chúng ta sẽ xây dựng ARC (Academic Research Chatbot) - một hệ thống chatbot thông minh hoạt động trên nền tảng AWS Serverless. Giải pháp này ứng dụng Generative AI và RAG (Retrieval-Augmented Generation) để hỗ trợ nghiên cứu học thuật, truy vấn tài liệu và trả lời câu hỏi một cách linh hoạt.\nThay vì trả lời các câu hỏi dựa trên kịch bản cố định (rule-based), hệ thống sử dụng mô hình Claude 3.5 Sonnet để hiểu ngôn ngữ tự nhiên, truy vấn dữ liệu từ cơ sở vector database và phản hồi người dùng một cách chính xác.\nMục tiêu Workshop Sau khi hoàn thành workshop, bạn sẽ:\nHiểu kiến trúc RAG và cách áp dụng vào thực tế Triển khai hệ thống chatbot hoàn chỉnh trên AWS Sử dụng Amazon Bedrock (Claude 3.5 Sonnet + Cohere Embed) Xây dựng IDP pipeline với Amazon Textract Implement vector search với Qdrant Deploy infrastructure với Terraform Tích hợp authentication với Amazon Cognito Nội dung Giới thiệu Các bước chuẩn bị Kích hoạt Bedrock Models Cấu hình AWS CLI Chuẩn bị Dữ liệu Triển khai Infrastructure Thiết lập Backend API Thiết lập IDP Pipeline Thiết lập Frontend Sử dụng Chatbot Sử dụng Admin Dashboard Dọn dẹp Tài nguyên "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại Công ty TNHH Amazon Web Services Vietnam từ 08/09/2025 đến 09/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia học tập và thực hành qua các workshop chuyên sâu về điện toán đám mây AWS, qua đó cải thiện kỹ năng làm việc với dịch vụ đám mây, phân tích công nghệ, viết báo cáo kỹ thuật và giao tiếp trong môi trường chuyên nghiệp.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ☐ ✅ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ☐ ✅ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Điểm mạnh Tiếp thu kiến thức mới nhanh. Tuân thủ các nguyên tắc trong công việc Có trách nhiệm với công việc được giao. Hòa đồng, hỗ trợ tốt trong làm việc nhóm. Điểm cần cải thiện Tự tin giao tiếp: Cần chủ động hơn về mặc giao tiếp Đào sâu vấn đề: Tìm tòi sâu giải pháp xử lí công việc thay vì là bề mặt Kế hoạch phát triển Lập thời gian biểu chi tiết cho việc học và ôn tập hợp lí hơn. Tích cực tham gia phát biểu trong các buổi thảo luận. "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Tìm hiểu tổng quan các dịch vụ lưu trữ trên AWS (S3, Glacier, Backup, Storage Gateway, Snow Family). Nắm rõ cách S3 hoạt động: access point, storage class, CORS, static website hosting. Thực hành toàn bộ quy trình với S3, Backup, Storage Gateway, File System. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu tổng quan các dịch vụ lưu trữ AWS: S3, EBS, Backup, Storage Gateway, Snow Family - Tìm hiểu Access Point, Storage Class và các mô hình truy cập dữ liệu - Nắm rõ S3 static website, CORS, Object key, Glacier 13/10/2025 13/10/2025 https://youtu.be/hsCfP0IxoaM?si=O3vMWs7Trr1fugJD https://youtu.be/_yunukwcAwc?si=ZhkTKr-_OkyUNImI https://youtu.be/mPBjB6Ltl_Q?si=qs6j0n7AeD2Mxwbz https://youtu.be/YXn8Q_Hpsu4?si=XojTnkR_LLC1KwEv 3 Thực hành: + Create S3 bucket + Deploy hạ tầng backup + Create backup plan và set up notification + Test restore và Dọn dẹp tài nguyên backup 14/10/2025 14/10/2025 https://000013.awsstudygroup.com 4 - Tìm hiểu VMware Workstation - Thực hành: + Export VM từ on-prem + Upload VM lên AWS + Import thành EC2 + Export lại thành AMI + Dọn dẹp môi trường import/export 15/10/2025 15/10/2025 https://000014.awsstudygroup.com 5 - Thực hành: + Create Storage Gateway + Create File Share nâng cao + kết nối File Share trên máy on-prem + Dọn dẹp Storage Gateway + File Shares 16/10/2025 16/10/2025 https://000024.awsstudygroup.com 6 - Thực hành(lab25): + Create FSx file system (SSD/HDD, Multi-AZ) + Create và cấu hình file shares + Test và giám sát hiệu năng + Quản lý user sessions + quotas - Thực hành(lab57): + Create bucket, upload dữ liệu, bật static website + Cấu hình public access + set quyền đối tượng + Create và cấu hình CloudFront phân phối nội dung\n+ Enable versioning và replication object - Dọn dẹp môi trường(lab25) bucket, CloudFront, replication 17/10/2025 17/10/2025 https://000025.awsstudygroup.com https://000057.awsstudygroup.com Kết quả đạt được tuần 6: Tổng quát:\nTrong tuần này tôi đã nắm được hệ sinh thái lưu trữ của AWS như S3, Glacier, Backup, Storage Gateway và các file system. Tập trung thực hành nhiều để hiểu cách quản lý dữ liệu, backup–restore và các cơ chế lưu trữ của AWS. Lý thuyết đã học:\nKhái niệm về S3 Storage Class, Access Point, CORS Học về Glacier, lifecycle, backup concepts Storage Gateway, file system kiến trúc Import/export máy ảo Thực hành với bài lab:\nBackup \u0026amp; restore Import máy ảo on-prem lên AWS Tạo file system Multi-AZ Tạo static website, CloudFront, versioning, replication Thực hành Storage Gateway – tạo file share, Kết nối thử, kiểm tra truyền dữ liệu giữa on-prem và AWS "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/5-workshop/5.6-infrastructure/","title":"Triển khai giải pháp","tags":[],"description":"","content":"Trong phần này, chúng ta sẽ clone repository và triển khai toàn bộ hạ tầng AWS cho hệ thống ARC Chatbot.\nBước 1: Clone Repository Clone repository từ GitHub:\ngit clone https://github.com/CrystalJohn/ARC-project.git cd ARC-project Bước 2: Build Dashboard Trước khi triển khai ứng dụng, chúng ta cần build frontend dashboard.\nDi chuyển đến thư mục frontend cd frontend Cài đặt dependencies Chạy lệnh sau để cài đặt các thư viện cần thiết:\nnpm install Build Dashboard Sau khi cài đặt hoàn tất, chạy lệnh build:\nnpm run build Sau khi quá trình hoàn tất, một thư mục dist sẽ được tạo. Kiểm tra file index.html và thư mục assets:\nls dist/ # index.html assets/ Quay lại thư mục gốc của project cd .. Bước 3: Triển khai CDK Application Triển khai ứng dụng CDK. Quá trình sẽ mất khoảng 20-30 phút để triển khai tất cả các tài nguyên.\ncd terraform terraform init terraform apply --auto-approve ⚠️ Note: Nếu bạn gặp lỗi ở bước này, hãy đảm bảo Docker đang chạy trên máy tính của bạn.\n💡 Info: Thay thế \u0026lt;account_id\u0026gt; bằng AWS Account ID thực tế của bạn.\nBước 4: Xác minh Triển khai Sau khi hoàn thành tất cả các bước trên, môi trường của bạn đã được triển khai thành công.\nBạn có thể xác minh triển khai bằng cách kiểm tra:\nAWS Console: Kiểm tra các resources đã được tạo (EC2, S3, Cognito, DynamoDB, etc.) Terraform State: Chạy terraform state list để xem danh sách resources S3 Buckets: Bucket cho documents và frontend đã được tạo EC2 Instance: Instance cho backend đã được khởi tạo Kiểm tra Outputs terraform output Các outputs quan trọng:\nOutput Mô tả api_endpoint Backend API URL cognito_user_pool_id Cognito User Pool ID cognito_client_id Cognito App Client ID s3_bucket_name S3 bucket cho documents cloudfront_url Frontend URL Các Bước Tiếp Theo Bây giờ bạn có thể tiếp tục:\nThiết lập Backend Thiết lập IDP Pipeline Thiết lập Frontend "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc tại AWS thông qua chương trình FCJ rất chuyên nghiệp và có nhiều sự hỗ trợ. Không gian học tập và làm việc được tổ chức một cách nghiêm túc và được vận hành tốt, giúp có thể tập trung học hỏi và tiếp thu kiến thức một cách hiệu quả nhất. Thông qua đó, AWS đã tổ chức các buổi workshop thường xuyên giúp em bổ sung kiến thức và cập nhập công nghệ mới hiện có.\n2. Sự hỗ trợ của mentor / team admin\nMentor luôn hướng dẫn em rất chi tiết, giải thích rõ ràng khi em chưa hiểu và luôn khuyến khích em đặt câu hỏi để học tốt hơn. Em đặc biệt trân trọng việc mentor cho phép em tự thử và tự giải quyết vấn đề thay vì chỉ đưa đáp án, giúp em chủ động và tiến bộ nhanh. Bên cạnh đó, team admin cũng luôn nhiệt tình hỗ trợ, chuẩn bị đầy đủ thủ tục và tài liệu, tạo điều kiện để em làm việc thuận lợi. Khi em có bất kỳ thắc mắc nào, mentor và team admin luôn phản hồi nhanh, giải đáp chi tiết và động viên em cố gắng học tập mỗi ngày.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nTrong quá trình thực tập, em đã học được rất nhiều kỹ năng quan trọng, từ kỹ thuật như làm việc với các dịch vụ AWS, cho đến kỹ năng mềm như phối hợp nhóm, trình bày và viết báo cáo. Đặc biệt, những buổi sharing từ các chuyên gia và anh hiện đang là việc tại FCJ đã mang đến cho em nhiều góc nhìn mới và là cơ hội quý giá để em mở rộng kiến thức cũng như định hướng phát triển bản thân.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người luôn tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn giữ được sự vui vẻ. Khi có dự án gấp, tất cả đều cùng nhau nỗ lực và hỗ trợ mà không phân biệt vị trí hay vai trò.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi em cần. Bên cạnh đó, việc được tham gia các buổi đào tạo nội bộ, workshop và chia sẻ kiến thức cũng là một điểm cộng lớn, giúp em học hỏi thêm nhiều kỹ năng thực tế.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\nTrong suốt thời gian thực tập, em hài lòng nhất khi được tham gia trực tiếp vào các công việc liên quan đến DevOps và AWS. Việc được tự tay triển khai hạ tầng, cấu hình dịch vụ và xử lý các vấn đề thực tế giúp em tiến bộ rất nhanh. Em cũng học hỏi được nhiều tư duy DevSecOps từ mentor, đặc biệt là trong quản lý IAM, CI/CD và vận hành hệ thống.\nĐiều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau?\nEm nghĩ công ty có thể bổ sung thêm các buổi thực hành DevOps nâng cao, chẳng hạn như xây dựng CI/CD pipeline hoàn chỉnh, mô phỏng sự cố (incident simulation) hoặc làm thêm mini-project theo nhóm. Điều này sẽ giúp thực tập sinh có góc nhìn rộng hơn về vận hành hệ thống trong thực tế.\nNếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao?\nCó! Chương trình mang lại kiến thức DevOps và AWS rất thực tế, được thực hành chứ không chỉ học lý thuyết. Mentor hỗ trợ tận tâm, môi trường chuyên nghiệp nhưng thân thiện, và đặc biệt phù hợp cho sinh viên muốn theo hướng Cloud/DevOps.\nĐề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập?\nEm nghĩ là chương trình thêm những bài thực thành theo nhóm rồi mới làm một bài tổng kết.\nBạn có muốn tiếp tục chương trình này trong tương lai? Nếu được tiếp tục, em hy vọng sẽ được tham gia vào các nội dung nâng cao hơn, chẳng hạn như xây dựng hệ thống DevOps hoàn chỉnh, triển khai CI/CD đa môi trường, tối ưu chi phí AWS\n"},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Tìm hiểu toàn bộ IAM: user, group, role, policy, permission boundary. Tìm hiểu cơ chế xác thực và phân quyền trong AWS, cách viết policy JSON và cách evaluate. Làm quen AWS Organizations, OU, Service Control Policy (SCP). Thực hành lab IAM + Organization để hình dung cách quản lý tài khoản ở quy mô lớn. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu tổng quan IAM: user, group, role, policy - Nắm cách hoạt động của policy evaluation: explicit deny, implicit deny, allow 20/10/2025 20/10/2025 https://youtu.be/tsobAlSg19g?si=9f3mlIWPtrCcNuKg https://youtu.be/N_vlJGAqZxo?si=e8oiWCObco95CoKh 3 - Thực hành: + Create user/group/role + Gán inline policy \u0026amp; managed policy + Test truy cập S3/EC2 theo từng policy - Tìm hiểu permission boundary và session policy 21/10/2025 21/10/2025 https://000028.awsstudygroup.com 4 - Tìm hiểu AWS Organizations: cấu trúc OU, tạo nhiều account - Khái niệm SCP, deny list, allow list 22/10/2025 22/10/2025 https://youtu.be/5oQY8Rogz9Y?si=h8DlUb8ZLI4HbbvM https://youtu.be/NW1xrMkNMjU?si=dhT0T3y2JYVK8QwT 5 - Thực hành: + Create Organization + OU + Áp dụng SCP deny Ec2 / deny S3 + Kiểm tra hiệu lực SCP kết hợp IAM polic + Sắp xếp lại OU, remove SCP 23/10/2025 23/10/2025 https://000030.awsstudygroup.com https://000044.awsstudygroup.com/ 6 - Làm việc nhóm: + Thảo luận ý tưởng về workshop + Cách thực hiện + Chia phần cho workshop 24/10/2025 24/10/2025 Kết quả đạt được tuần 7: Tổng quát:\nTrong tuần này tôi đã nắm được nền tảng quản lý truy cập AWS, bao gồm IAM và Organizations. Hiểu cách vận hành của policy, cách viết, cách đánh giá quyền, và cách áp dụng SCP trong môi trường nhiều account. Lý thuyết đã học:\nKhái niệm về User – Group – Role – Policy và cơ chế evaluate Inline policy, managed policy, permission boundary Cấu trúc AWS Organizations, OU Khái niệm SCP và sự khác biệt so với IAM policy Landing Zone – Control Tower overview Thực hành với bài lab:\nTạo user/group/role và test truy cập Viết policy JSON và thử deny/allow theo từng hành vi Tạo Organization, OU và áp SCP Kiểm tra sự kết hợp SCP + IAM policy trong thực tế "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/5-workshop/5.7-backend/","title":"Thiết lập Backend API","tags":[],"description":"","content":"Thiết lập Backend API Trong phần này, bạn sẽ cấu hình Backend API (FastAPI) và Qdrant vector database trên EC2.\nKiến trúc Backend Internet → ALB (:80) → EC2 Private Subnet ├── FastAPI Container (:8000) ├── Qdrant Container (:6333) └── SQS Worker (background) 💡 Note: EC2 nằm trong Private Subnet, không có Public IP. Truy cập qua SSM Session Manager.\nBước 1: Truy cập EC2 qua Session Manager EC2 instance đã được tạo trong Private Subnet và không có Public IP. Sử dụng AWS Systems Manager Session Manager để truy cập.\nCách 1: AWS Console Mở AWS Console → EC2 → Instances Chọn instance arc-dev-app-server Click Connect → Session Manager → Connect Cách 2: AWS CLI # Lấy Instance ID từ Terraform output INSTANCE_ID=$(terraform -chdir=terraform output -raw ec2_instance_id) # Kết nối qua SSM aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1 ⚠️ Yêu cầu: Cài đặt Session Manager Plugin\nBước 2: Kiểm tra Services đã chạy EC2 đã được setup tự động qua user_data script khi Terraform tạo instance. Kiểm tra các services:\n# Chuyển sang ec2-user sudo su - ec2-user # Kiểm tra Docker containers docker ps Bạn sẽ thấy 2 containers đang chạy:\napp-fastapi-1 - FastAPI server (port 8000) app-qdrant-1 - Qdrant vector database (port 6333) # Kiểm tra Qdrant curl http://localhost:6333/collections # Kiểm tra FastAPI curl http://localhost:8000/health Bước 3: Deploy Backend Code Backend code sẽ được deploy qua CI/CD Pipeline (CodePipeline → CodeBuild → CodeDeploy). Tuy nhiên, để test nhanh, bạn có thể deploy thủ công:\ncd /home/ec2-user # Clone repository git clone https://github.com/CrystalJohn/ARC-project.git cd ARC-project/backend # Stop containers cũ cd /home/ec2-user/app docker-compose down # Copy backend code cp -r /home/ec2-user/ARC-project/backend/* /home/ec2-user/app/ # Start với code mới docker-compose up -d --build Bước 4: Cấu hình Environment Variables Tạo file .env với các giá trị từ Terraform outputs:\ncd /home/ec2-user/app # Lấy values từ Terraform outputs (chạy trên máy local) # terraform -chdir=terraform output cat \u0026gt; .env \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; # AWS Configuration AWS_REGION=ap-southeast-1 # S3 S3_BUCKET_NAME=arc-documents-\u0026lt;account-id\u0026gt; # DynamoDB DYNAMODB_TABLE_NAME=arc-dev-documents # SQS SQS_QUEUE_URL=https://sqs.ap-southeast-1.amazonaws.com/\u0026lt;account-id\u0026gt;/arc-dev-document-queue # Qdrant (local container) QDRANT_HOST=qdrant QDRANT_PORT=6333 # Cognito COGNITO_USER_POOL_ID=ap-southeast-1_xxxxx COGNITO_CLIENT_ID=xxxxx # Bedrock BEDROCK_MODEL_ID=anthropic.claude-3-5-sonnet-20241022-v2:0 EMBEDDING_MODEL_ID=amazon.titan-embed-text-v2:0 EOF 💡 Tip: Thay \u0026lt;account-id\u0026gt; và các giá trị xxxxx bằng outputs thực tế từ Terraform.\nBước 5: Restart Services # Restart để load .env mới docker-compose down docker-compose up -d # Kiểm tra logs docker-compose logs -f fastapi Bước 6: Verify qua ALB Backend được expose qua Application Load Balancer. Kiểm tra từ máy local:\n# Lấy ALB DNS từ Terraform output ALB_DNS=$(terraform -chdir=terraform output -raw alb_dns_name) # Test health endpoint curl http://$ALB_DNS/health # {\u0026#34;status\u0026#34;:\u0026#34;healthy\u0026#34;} Bước 7: Kiểm tra Qdrant Collection # Trên EC2 curl http://localhost:6333/collections # Tạo collection cho documents (nếu chưa có) curl -X PUT http://localhost:6333/collections/documents \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;vectors\u0026#34;: { \u0026#34;size\u0026#34;: 1024, \u0026#34;distance\u0026#34;: \u0026#34;Cosine\u0026#34; } }\u0026#39; 💡 Note: Vector size 1024 tương ứng với Amazon Titan Embeddings v2.\nChecklist Truy cập EC2 qua Session Manager thành công Docker containers đang chạy (fastapi, qdrant) File .env đã được cấu hình Health check qua ALB thành công Qdrant collection đã được tạo Troubleshooting Không thể kết nối Session Manager # Kiểm tra SSM Agent trên EC2 sudo systemctl status amazon-ssm-agent # Kiểm tra IAM Role có policy AmazonSSMManagedInstanceCore Container không start # Xem logs docker-compose logs # Kiểm tra disk space df -h ALB health check fail # Kiểm tra Security Group cho phép port 8000 từ ALB # Kiểm tra FastAPI đang listen trên 0.0.0.0:8000 docker-compose logs fastapi "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Tìm hiểu hệ thống cơ sở dữ liệu trên AWS: RDS, Aurora, Redshift, ElastiCache. Thực hành xây dựng database subnet group, test kết nối, backup \u0026amp; restore. Tìm hiểu các dịch vụ phân tích dữ liệu như Kinesis, Glue, Athena, QuickSight. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về Database: RDS, Aurora, Redshift, ElastiCache - Tìm hiểu về kiến trúc multi-AZ, read replica, backup/restore 27/10/2025 27/10/2025 https://youtu.be/OOD2RwWuLRw?si=9JsOs0PNfO1TdAUl https://youtu.be/qbrobQZrokY?si=ePJjzYXWg3qE_Ca6 https://youtu.be/UvdiRW34aNI?si=8g3FwgsJ3VLT-_nf 3 - Thực hành: + Create VPC + SG cho EC2 + RDS + Create DB subnet group + Deploy EC2 + Tạo RDS instance + Backup \u0026amp; Restore 28/10/2025 28/10/2025 https://000005.awsstudygroup.com 4 - Thực hành: + Kết nối MSSQL/Oracle + Schema Conversion + Create DMS Task + Inspect logs, troubleshoot 29/10/2025 29/10/20255 https://000043.awsstudygroup.com 5 - Tìm hiểu tổng quan về Data Analytics (Kinesis, Glue, Athena, QuickSight) - Thực hành: + Create DynamoDB table + Enable autoscaling + CRUD test Create Global Table và dọn dẹp resources 30/10/2025 30/10/2025 https://000039.awsstudygroup.com 6 - Thực hành(lab35): + Create S3 bucket + Create Kinesis Firehose ingestion + Glue crawler + Query dữ liệu bằng Athena + Create dashboard QuickSight - Thực hành(lab40): + Kiểm tra cost allocation + CTagging resource + Query bổ sung và dọn dẹp Resources 31/10/2025 31/10/2025 https://000035.awsstudygroup.com https://000040.awsstudygroup.com Kết quả đạt được tuần 8: Tổng quát:\nTrong tuần này tôi tập trung học các dịch vụ database và data analytics trên AWS, bao gồm RDS, Aurora, DynamoDB, DMS, Kinesis, Glue, Athena và QuickSight. Tôi hiểu rõ kiến trúc triển khai database, cách kết nối, backup/restore, autoscaling cũng như pipeline phân tích dữ liệu đầu cuối từ ingestion -\u0026gt; ETL -\u0026gt; query -\u0026gt; visualization. Lý thuyết đã học:\nKhái niệm về Kiến trúc của RDS, Aurora, Multi-AZ, read replicas Backup, snapshot, parameter group, option group DynamoDB: partition key, sort key, throughput, autoscaling, DAX Tổng quan Data Analytics: Kinesis Firehose, Glue crawler, Athena, QuickSight Kiến thức về Database Migration: schema conversion, DMS task Thực hành với bài lab:\nTạo VPC + security group riêng cho EC2/RDS Tạo DB subnet group, deploy EC2 và RDS MySQL Backup \u0026amp; Restore database Kết nối MSSQL/Oracle, thực hành Schema Conversion \u0026amp; tạo DMS task Tạo DynamoDB table, bật autoscaling, CRUD test, tạo Global Table và cleanup Xây dựng pipeline: Kinesis Firehose -\u0026gt; S3, chạy Glue crawler, query dữ liệu bằng Athena và dựng dashboard trên QuickSight. Thực hành các tác vụ bổ sung: tagging, cost allocation và cleanup "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/5-workshop/5.8-idp-pipeline/","title":"Thiết lập IDP Pipeline","tags":[],"description":"","content":"Trong phần này, bạn sẽ setup SQS Worker để xử lý documents qua IDP (Intelligent Document Processing) pipeline.\nIDP Flow Upload → S3 → DynamoDB (UPLOADED) → SQS ↓ EC2 Worker ↓ PyPDF2 (digital) / Textract (scanned) ↓ Chunk Text (1000 tokens) ↓ Cohere Embed Multilingual v3 (Bedrock) ↓ Qdrant (store vectors) ↓ DynamoDB (EMBEDDING_DONE) 💡 Note: Worker sử dụng PyPDF2 cho PDF digital (text-based) và Textract cho PDF scanned (image-based).\nDocument States Status Description UPLOADED File đã upload, đang chờ xử lý IDP_RUNNING Worker đang xử lý TEXTRACT_DONE OCR hoàn tất (chỉ cho scanned PDF) EMBEDDING_DONE Hoàn tất, sẵn sàng sử dụng FAILED Có lỗi xảy ra Bước 1: Truy cập EC2 qua Session Manager # Lấy Instance ID INSTANCE_ID=$(terraform -chdir=terraform output -raw ec2_instance_id) # Kết nối aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1 Sau khi kết nối:\nsudo su - ec2-user cd /home/ec2-user/backend 💡 Note: Trên EC2 có 2 folders:\napp/ - Boilerplate từ user_data script backend/ - Code thực tế được deploy qua CI/CD (chứa run_worker.py) Bước 2: Kiểm tra Worker Code Worker code nằm trong backend/run_worker.py. Kiểm tra file đã có:\nls -la # Phải có: run_worker.py, app/, requirements.txt Bước 3: Cấu hình Environment Đảm bảo file .env có đầy đủ các biến (trong folder backend/):\ncd /home/ec2-user/backend cat .env Các biến quan trọng cho IDP:\nSQS_QUEUE_URL=https://sqs.ap-southeast-1.amazonaws.com/\u0026lt;account\u0026gt;/arc-dev-document-queue S3_BUCKET=arc-documents-\u0026lt;account\u0026gt; QDRANT_HOST=localhost QDRANT_PORT=6333 AWS_REGION=ap-southeast-1 Bước 4: Start Worker Option A: Chạy trực tiếp (để debug) # Activate virtual environment (nếu có) source venv/bin/activate # Chạy worker python run_worker.py Worker sẽ hiển thị:\n============================================================ IDP Pipeline - SQS Worker ============================================================ Queue URL: https://sqs.ap-southeast-1.amazonaws.com/xxx/arc-dev-document-queue Bucket: arc-documents-xxx Region: ap-southeast-1 Qdrant: localhost:6333 ------------------------------------------------------------ Processing indefinitely (Ctrl+C to stop)... Option B: Chạy trong background với nohup nohup python run_worker.py \u0026gt; worker.log 2\u0026gt;\u0026amp;1 \u0026amp; # Kiểm tra process ps aux | grep run_worker # Xem logs tail -f worker.log Option C: Chạy trong Docker (recommended) # Thêm worker vào docker-compose.yml docker-compose up -d worker Bước 5: Test IDP Pipeline 5.1 Upload test file lên S3 # Từ máy local aws s3 cp test-sample.pdf s3://arc-documents-\u0026lt;account\u0026gt;/uploads/test-001.pdf 5.2 Tạo record trong DynamoDB aws dynamodb put-item \\ --table-name arc-dev-documents \\ --item \u0026#39;{ \u0026#34;doc_id\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;test-001\u0026#34;}, \u0026#34;sk\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;METADATA\u0026#34;}, \u0026#34;filename\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;test-sample.pdf\u0026#34;}, \u0026#34;s3_key\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;uploads/test-001.pdf\u0026#34;}, \u0026#34;status\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;UPLOADED\u0026#34;}, \u0026#34;uploaded_at\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$(date -u +%Y-%m-%dT%H:%M:%SZ)\u0026#39;\u0026#34;} }\u0026#39; 5.3 Gửi message vào SQS aws sqs send-message \\ --queue-url https://sqs.ap-southeast-1.amazonaws.com/\u0026lt;account\u0026gt;/arc-dev-document-queue \\ --message-body \u0026#39;{ \u0026#34;doc_id\u0026#34;: \u0026#34;test-001\u0026#34;, \u0026#34;s3_key\u0026#34;: \u0026#34;uploads/test-001.pdf\u0026#34;, \u0026#34;filename\u0026#34;: \u0026#34;test-sample.pdf\u0026#34; }\u0026#39; Bước 6: Monitor Processing Xem logs của worker:\n# Nếu chạy trực tiếp # Logs hiển thị trên terminal # Nếu chạy background tail -f worker.log Logs thành công sẽ như sau:\n2024-01-15 10:30:00 - INFO - Received message for doc_id: test-001 2024-01-15 10:30:01 - INFO - Downloading from S3: uploads/test-001.pdf 2024-01-15 10:30:02 - INFO - Extracting text with PyPDF2... 2024-01-15 10:30:03 - INFO - Created 8 chunks from document 2024-01-15 10:30:05 - INFO - Generating embeddings with Cohere... 2024-01-15 10:30:10 - INFO - Stored 8 vectors for test-001 2024-01-15 10:30:10 - INFO - Updated status: EMBEDDING_DONE 2024-01-15 10:30:10 - INFO - Document test-001 processed successfully Bước 7: Verify Processing 7.1 Kiểm tra DynamoDB aws dynamodb get-item \\ --table-name arc-dev-documents \\ --key \u0026#39;{\u0026#34;doc_id\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;test-001\u0026#34;},\u0026#34;sk\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;METADATA\u0026#34;}}\u0026#39; \\ --query \u0026#39;Item.{status:status.S,chunks:chunk_count.N}\u0026#39; Expected output:\n{ \u0026#34;status\u0026#34;: \u0026#34;EMBEDDING_DONE\u0026#34;, \u0026#34;chunks\u0026#34;: \u0026#34;8\u0026#34; } 7.2 Kiểm tra Qdrant # Trên EC2 curl -s http://localhost:6333/collections/arc_documents/points/count | jq Expected output:\n{ \u0026#34;result\u0026#34;: { \u0026#34;count\u0026#34;: 8 } } Xử lý Lỗi Vấn đề Nguyên nhân Giải pháp Worker không nhận message SQS URL sai Kiểm tra .env Bedrock timeout Rate limit Tăng retry delay Qdrant connection refused Container chưa start docker-compose up -d qdrant FAILED status Xem error_message trong DynamoDB Fix và retry Retry Failed Document # Cập nhật status về UPLOADED để retry aws dynamodb update-item \\ --table-name arc-dev-documents \\ --key \u0026#39;{\u0026#34;doc_id\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;test-001\u0026#34;},\u0026#34;sk\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;METADATA\u0026#34;}}\u0026#39; \\ --update-expression \u0026#34;SET #s = :s\u0026#34; \\ --expression-attribute-names \u0026#39;{\u0026#34;#s\u0026#34;:\u0026#34;status\u0026#34;}\u0026#39; \\ --expression-attribute-values \u0026#39;{\u0026#34;:s\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;UPLOADED\u0026#34;}}\u0026#39; # Gửi lại message vào SQS aws sqs send-message \\ --queue-url $SQS_QUEUE_URL \\ --message-body \u0026#39;{\u0026#34;doc_id\u0026#34;:\u0026#34;test-001\u0026#34;,\u0026#34;s3_key\u0026#34;:\u0026#34;uploads/test-001.pdf\u0026#34;,\u0026#34;filename\u0026#34;:\u0026#34;test-sample.pdf\u0026#34;}\u0026#39; Checklist Truy cập EC2 qua Session Manager Worker code có sẵn Environment variables configured Worker đang chạy Test document uploaded to S3 SQS message sent Worker processed document (logs) Status = EMBEDDING_DONE trong DynamoDB Vectors stored trong Qdrant "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Tìm hiểu tổng quan kiến trúc Serverless và các thành phần chính: API Gateway, Lambda, DynamoDB. Thiết kế kiến trúc tổng thể cho ứng dụng: backend, frontend, xác thực, bảo mật và tích hợp. Nghiên cứu lớp bảo mật (Edge \u0026amp; Security): CloudFront, Route 53, WAF. Tìm hiểu hệ thống xác thực với Amazon Cognito và cách cấp token cho API. Phân tích cách triển khai CI/CD với CodePipeline, CodeBuild, GitLab và IaC (CloudFormation). Tìm hiểu hệ thống quan sát/giám sát: CloudWatch, X-Ray, SNS. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu kiến trúc Serverless - API Gateway, Lambda, DynamoDB \u0026amp; cơ chế tích hợp 03/11/2025 03/11/2025 3 - Thiết kế kiến trúc tổng thể (BE + FE + Auth + Edge) - Vẽ sơ đồ kiến trúc \u0026amp; luồng request 04/11/2025 04/11/2025 4 - Tìm hiểu CloudFront, Route 53, WAF - Thiết kế lớp bảo mật trước API Gateway 05/11/2025 05/11/2025 5 - Tìm hiểu Cognito (User Pool, Token) - Phân tích cách API Gateway validate JWT token 06/11/2025 06/11/2025 6 - Tìm hiểu CI/CD: CloudFormation, CodePipeline, CodeBuild - Hệ thống quan sát: CloudWatch, X-Ray, SNS 07/11/2025 07/11/2025 Kết quả đạt được tuần 9: Tổng quát:\nTrong tuần này tôi tập trung hiểu và thiết kế kiến trúc Serverless cho ứng dụng. Tôi đã nắm rõ luồng hoạt động của API Gateway – Lambda – DynamoDB, đồng thời nghiên cứu lớp bảo mật bằng CloudFront/WAF và hệ thống xác thực bằng Cognito. Tôi cũng nắm được quy trình CI/CD và cơ chế logging/monitoring để chuẩn bị cho các tuần code tiếp theo. Lý thuyết đã học:\nKiến trúc Serverless, nguyên tắc pay-per-use và autoscaling. API Gateway REST API, Lambda integration, DynamoDB table workflow. CloudFront + WAF + Route 53 để bảo vệ API. Cognito User Pool \u0026amp; Token (ID/Access), JWT flow qua API Gateway authorizer. CI/CD với CodePipeline + CodeBuild + CloudFormation. CloudWatch logs/metrics, SNS alert, tracing bằng X-Ray. Thực hành / Sản phẩm:\nSơ đồ kiến trúc tổng thể ứng dụng (BE – FE – Auth – Edge). Luồng request từ client -\u0026gt; CloudFront -\u0026gt; API Gateway -\u0026gt; Lambda -\u0026gt; DynamoDB. Diagram bảo mật: CDN, DNS, WAF, throttling \u0026amp; protection tại API Gateway. Phác thảo pipeline tự động triển khai bằng CloudFormation \u0026amp; CodePipeline. Thiết kế flow xác thực Cognito -\u0026gt; API Gateway JWT Authorizer. "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/5-workshop/5.9-frontend/","title":"Thiết lập Frontend","tags":[],"description":"","content":"Thiết lập Frontend Cấu hình và deploy Frontend React application với AWS Amplify.\nBước 1: Lấy Terraform Outputs cd terraform terraform output Ghi lại: cognito_user_pool_id, cognito_client_id, alb_dns_name\nBước 2: Cấu hình Environment cd ARC-project cp .env.example .env Chỉnh sửa .env:\nVITE_AWS_REGION=ap-southeast-1 VITE_COGNITO_POOL_ID=ap-southeast-1_xxxxxxx VITE_COGNITO_CLIENT_ID=xxxxxxxxxxxxxxxxxxxxxxxxxx VITE_API_URL=http://arc-chatbot-dev-alb-xxxxx.ap-southeast-1.elb.amazonaws.com Bước 3: Install \u0026amp; Test Local npm install npm run dev Mở http://localhost:5173\nBước 4: Build \u0026amp; Deploy npm run build Push code lên GitHub, Amplify sẽ tự động deploy:\ngit add . git commit -m \u0026#34;Update frontend config\u0026#34; git push origin main 💡 Amplify app đã được tạo qua Terraform và connected với GitHub.\nBước 5: Cập nhật Cognito Callback URLs Sau khi có Amplify URL:\naws cognito-idp update-user-pool-client \\ --user-pool-id ap-southeast-1_xxxxxxx \\ --client-id xxxxxxxxxx \\ --callback-urls \u0026#34;http://localhost:5173\u0026#34; \u0026#34;https://main.xxxxx.amplifyapp.com\u0026#34; \\ --logout-urls \u0026#34;http://localhost:5173\u0026#34; \u0026#34;https://main.xxxxx.amplifyapp.com\u0026#34; Bước 6: Tạo Test Users # Admin user aws cognito-idp admin-create-user \\ --user-pool-id ap-southeast-1_xxxxxxx \\ --username admin@example.com \\ --user-attributes Name=email,Value=admin@example.com \\ --temporary-password \u0026#34;TempPass123!\u0026#34; aws cognito-idp admin-add-user-to-group \\ --user-pool-id ap-southeast-1_xxxxxxx \\ --username admin@example.com \\ --group-name admin Xử lý Lỗi Lỗi Giải pháp CORS error Kiểm tra FastAPI CORS config \u0026ldquo;User pool does not exist\u0026rdquo; Kiểm tra VITE_COGNITO_POOL_ID Build failed Kiểm tra Amplify environment variables Checklist .env đã cấu hình Local dev server chạy được Amplify deploy thành công Cognito callback URLs đã cập nhật Login/Register hoạt động "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Hoàn thiện 100% Backend CRUD bằng .NET chạy trên Aspire AppHost. Xây dựng và kiểm thử mô hình dữ liệu DynamoDB trên môi trường local (Docker). Tích hợp DynamoDB Local với NoSQL Workbench để validate mô hình. Làm việc cùng nhóm FE để hoàn thiện giao diện cơ bản và kết nối API local. Chuẩn bị nền tảng vững chắc trước khi chuyển sang tuần 11 (chuyển code lên Lambda + API Gateway). Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Kiểm tra \u0026amp; cài đặt lại môi trường BE: .NET SDK, Docker Desktop, NoSQL Workbench - Nắm sơ đồ kiến trúc hệ thống và luồng xử lý backend 10/11/2025 10/11/2025 3 - Setup DynamoDB Local bằng Docker - Kết nối \u0026amp; trực quan hóa bằng NoSQL Workbench, test CRUD thủ công 11/11/2025 11/11/2025 4 - Code DAL/Repository bằng .NET + AWSSDK.DynamoDBv2 - Tích hợp DI vào Aspire AppHost - Viết logic nghiệp vụ tại BLL 12/11/2025 12/11/2025 5 - Viết API Controllers CRUD - Test unit \u0026amp; integration trên môi trường local 13/11/2025 13/11/2025 6 - Làm việc chung với nhóm FE - Build giao diện sơ bộ (List/Create) - FE kết nối API Local, test end-to-end 14/11/2025 14/11/2025 Kết quả đạt được tuần 10: Tổng quát:\nTrong tuần này tôi đã hoàn thiện toàn bộ phần backend chạy local bằng Aspire AppHost, xây dựng mô hình dữ liệu DynamoDB, test CRUD và tích hợp với frontend. Nhờ đảm bảo kiến trúc và code local hoàn chỉnh, tôi có nền tảng vững chắc để chuyển sang Lambda/API Gateway ở tuần 11. Lý thuyết đã học:\nThiết kế dữ liệu DynamoDB theo Single-Table Design, Access Pattern, PK/SK. Kiến thức về DynamoDB Local, NoSQL Workbench, Docker setup. Cách sử dụng AWSSDK.DynamoDBv2 trong .NET và tích hợp DI. Cấu trúc Backend ASP.NET (Controller -\u0026gt; BLL -\u0026gt; Repository). Cách FE gọi API local, xử lý response và render dữ liệu. Thực hành / Sản phẩm:\nTạo DynamoDB Local bằng Docker và quản lý schema qua NoSQL Workbench. Build Repository + BLL + Controllers bằng .NET 8 / Aspire AppHost. Hoàn thiện 5–6 API CRUD (POST/GET/PUT/DELETE/List). Viết unit test cho BLL và integration test cho API. FE team triển khai giao diện List + Create và test thành công với API local. "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/5-workshop/5.10-using-chatbot/","title":"Sử dụng Chatbot","tags":[],"description":"","content":"Hướng dẫn sử dụng ARC Chatbot để tìm kiếm thông tin từ tài liệu nghiên cứu.\nTruy cập Local: http://localhost:5173 Production: Amplify URL từ bước trước Bước 1: Đăng nhập Nhập email và password Click Login Redirect đến Chat page Bước 2: Giao diện Chat Sau khi đăng nhập, bạn sẽ thấy:\nSidebar với menu Chat, History Header với user info và dark mode toggle Chat area với welcome message Bước 3: Đặt câu hỏi Nhập câu hỏi vào input box và nhấn Enter hoặc click Send.\nCâu hỏi tốt Loại Ví dụ Định nghĩa \u0026ldquo;What is a stack data structure?\u0026rdquo; So sánh \u0026ldquo;Compare stack and queue\u0026rdquo; Giải thích \u0026ldquo;Explain binary search algorithm\u0026rdquo; Tránh ❌ Quá chung: \u0026ldquo;Tell me about programming\u0026rdquo; ❌ Ngoài tài liệu: \u0026ldquo;What\u0026rsquo;s the weather today?\u0026rdquo; Bước 4: Citations (Trích dẫn) Mỗi câu trả lời có citations hiển thị nguồn tài liệu:\n📚 Sources: [1] data-structures.pdf - Page 12 - Score: 85% [2] algorithms.pdf - Page 45 - Score: 72% Click vào citation để xem chi tiết document.\nField Mô tả [1], [2] Số thứ tự citation Filename Tên file PDF Page Số trang Score Độ liên quan (%) Bước 5: Conversation History Click History trong sidebar Xem danh sách các cuộc hội thoại trước Click vào conversation để load lại Click trash icon để xóa Bước 6: New Chat Click New Chat trong sidebar để bắt đầu cuộc hội thoại mới.\nFeatures Feature Mô tả Streaming Response hiển thị từng phần Markdown Hỗ trợ code blocks, lists, headers Dark Mode Toggle trong header History Lưu và load lại conversations Checklist Đăng nhập thành công Gửi query và nhận response Citations hiển thị đúng Click citation xem document History hoạt động New Chat hoạt động "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Hoàn thiện giao diện FE cùng nhóm Frontend. Phối hợp kiểm thử end-to-end giữa FE và BE. Tìm hiểu quy trình deploy tổng thể hệ thống (API, FE, cơ sở dữ liệu, hạ tầng) để nắm kiến thức chung, dù không phải người chịu trách nhiệm chính. Chuẩn bị các ghi chú cần thiết cho tuần 12 (viết tài liệu \u0026amp; tổng kết). Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm việc chung với nhóm FE để hoàn thiện giao diện còn thiếu - - Rà soát lại API contract giữa FE và BE 17/11/2025 17/11/2025 3 - FE tích hợp API đầy đủ các luồng CRUD - Fix lỗi sai schema, payload, status code trong quá trình FE test 18/11/2025 18/11/2025 4 - Test end-to-end toàn bộ luồng: List -\u0026gt; Create -\u0026gt; Update -\u0026gt; Delete từ FE tới BEI - Cập nhật lại response model/validation cho phù hợp FE 19/11/2025 19/11/2025 \u0026lt; 5 - Tìm hiểu quy trình deploy của nhóm (CI/CD, API Gateway, Lambda, S3 + CloudFront) - Ghi chú các bước để chuẩn bị cho tuần 12 viết tài liệu 20/11/2025 20/11/2025 6 - Tổng hợp issue FE và BE trong tuần + - Rà soát lại toàn bộ phần BE để chuẩn bị cho môi trường deploy (dù không trực tiếp triển khai) 21/11/2025 21/11/20255 Kết quả đạt được tuần 11: Tổng quát:\nTrong tuần này tôi chủ yếu phối hợp với nhóm FE để hoàn thiện giao diện và tích hợp API. Sau khi BE đã xong ở tuần 10, tôi hỗ trợ fix lỗi, chuẩn hóa contract API và kiểm thử end-to-end. Ngoài ra, tôi cũng tìm hiểu quy trình deploy của nhóm (Lambda, API Gateway, S3/CloudFront, CI/CD) để chuẩn bị cho việc viết tài liệu ở tuần 12. Lý thuyết đã học:\nCách FE gọi API CRUD và debug request. API Contract: schema input/output, error format, status code. Quy trình deploy: .NET -\u0026gt; Lambda, API Gateway routing, FE build -\u0026gt; S3/CloudFront. Tổng quan CI/CD pipeline và chuẩn bị code cho deploy (config, logging). Thực hành / Sản phẩm:\nPhối hợp FE hoàn thiện màn hình List/Create/Update/Delete. Điều chỉnh backend theo yêu cầu FE (schema, validation, status code). Test end-to-end toàn bộ luồng FE ↔ BE trên local. Ghi chú quy trình deploy để dùng cho tuần 12. Tổng hợp lỗi FE và BE và cập nhật backlog nhóm. "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/5-workshop/5.11-admin-dashboard/","title":"Sử dụng Admin Dashboard","tags":[],"description":"","content":"Sử dụng Admin Dashboard Hướng dẫn sử dụng Admin Dashboard để quản lý documents.\nTruy cập URL: http://localhost:5173/admin (hoặc Amplify URL) Yêu cầu: Tài khoản thuộc group admin Bước 1: Đăng nhập Admin Đăng nhập với tài khoản admin (đã tạo ở bước trước).\nBước 2: Dashboard Overview Sau khi đăng nhập, bạn sẽ thấy:\nUpload section (drag \u0026amp; drop) Documents table với pagination Status filter và auto-refresh Bước 3: Upload Tài liệu 3.1. Chọn file Drag \u0026amp; drop PDF files vào vùng upload Hoặc click Browse Files để chọn 3.2. Upload Progress Mỗi file hiển thị progress bar và status:\nuploading - Đang upload success - Upload thành công error - Upload thất bại Bước 4: Document Status Sau khi upload, document sẽ được xử lý qua IDP pipeline:\nStatus Mô tả Thời gian UPLOADED Chờ xử lý - IDP_RUNNING Đang xử lý 1-5 phút EMBEDDING_DONE Sẵn sàng - FAILED Lỗi - 💡 Tip: Bật Auto-refresh (5s) để tự động cập nhật status.\nBước 5: Quản lý Documents Filter theo Status Sử dụng dropdown Status để lọc:\nAll Uploaded Processing Done Failed Pagination Documents được phân trang (5 items/page). Sử dụng pagination controls ở footer.\nView Document Click icon 👁️ để xem chi tiết document.\nDelete Document Click icon 🗑️ để xóa document.\n⚠️ Warning: Xóa document sẽ xóa khỏi S3, DynamoDB và Qdrant.\nBước 6: Processing History Click Processing History link để xem lịch sử xử lý documents.\nXử lý Lỗi Vấn đề Giải pháp Upload failed Kiểm tra file size (\u0026lt;50MB), format (PDF only) Document stuck in IDP_RUNNING Kiểm tra worker logs trên EC2 Document FAILED Xem error message trong Processing History Checklist Đăng nhập admin dashboard Upload document thành công Document processed (EMBEDDING_DONE) Filter/pagination hoạt động Auto-refresh hoạt động "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/1-worklog/1.12-week12/","title":"Nhật ký công việc","tags":[],"description":"","content":"Worklog Tuần 12 Mục tiêu Tuần 12 Nắm vững quy trình triển khai hạ tầng AWS bằng CDK và hiểu rõ mối quan hệ giữa các stack (VPC, RDS, Lambda, S3, API Gateway). Hoàn thiện logic backend cho module admin, bao gồm xử lý dữ liệu, analytics và cơ chế lưu trữ/archiving từ RDS → S3. Tối ưu cấu trúc hệ thống, refactor code backend và dashboard theo hướng tách riêng business layer – dễ bảo trì – dễ mở rộng. Nghiên cứu và triển khai các cải tiến để xử lý dữ liệu hiệu quả hơn (checksum, giới hạn dữ liệu load, tối ưu logic đồng bộ). Thành thạo quản lý tài nguyên AWS thông qua CLI và Console, đảm bảo có thể chạy nhiều lần deploy mà không bị xung đột. Các công việc cần thực hiện trong tuần Day Task Start Date Completion Date Reference Material 2 Refactor quy trình deploy và comment các thành phần analytics không sử dụng.\nĐiều chỉnh app.py để luôn deploy VPC, RDS và DB Init Stack; bật DashboardStack với dependency đúng.\nComment toàn bộ tài nguyên Glue, archive và analytics (Lambda/EventBridge + API) trong dashboard_stack.py.\nGiảm kích thước instance RDS (SMALL → MICRO) và đặt storage = 20GB. 24/11/2025 24/11/2025 3 Bắt đầu deploy AppStack, DashboardStack và DBInitStack để hỗ trợ backend cho admin.\nSửa lỗi do cấu hình max AZ = 1 khi tạo RDS (AWS yêu cầu tối thiểu 2 AZ). Mặc dù tạo 2 AZ, nhưng chế độ Multi-AZ không được bật, chỉ thêm subnet – nên không phát sinh thêm chi phí.\nRefactor API: xử lý body dạng string trả về từ API Gateway, cập nhật đường dẫn endpoint, cải thiện logging.\nCập nhật CDK: dùng secret đúng cho Lambda, cập nhật VPC/subnet, thêm rule SG cho HTTPS, comment endpoint Bedrock không dùng.\nCập nhật cơ chế đóng gói asset (dùng cp -r thay cho cp -au).\nTổ chức lại luồng nghiệp vụ admin: quản lý lịch hẹn, gán consultant cho timeslot và tạo báo cáo tổng hợp lịch hẹn hằng ngày.\nAdmin upload file SQL → ArchiveData lưu vào S3 → các lần deploy sau sẽ load từ S3 thay vì phải upload lại.\nĐịnh hướng tương lai: cho phép Lambda index.py đọc schema khi deploy và load dữ liệu từ S3 – khả thi.\nĐịnh hướng dài hạn: migrate toàn bộ dữ liệu on-premise lên S3; Lambda sẽ đẩy dữ liệu khởi tạo vào RDS ở lần deploy đầu tiên; các cập nhật dữ liệu mới sẽ do ArchiveData xử lý. 25/11/2025 25/11/2025 4 Hardcode schema trong index.py và xóa các file schema khỏi thư mục project.\nXử lý data mới và lưu CSV phục vụ cho việc tạo DDL Athena sau này.\nThêm API và UI tổng quan cho dashboard; refactor lại logic database cho admin.\nThêm API thống kê tổng hợp: tổng quan, khách hàng, consultant, lịch hẹn, chương trình cộng đồng; cập nhật UI dashboard để hiển thị các số liệu này.\nRefactor DatabasePage: loại bỏ tính năng chạy raw SQL, tập trung vào schema + analytics.\nCập nhật CDK + IAM role cho S3 bucket mới và phân quyền phù hợp.\nDi chuyển toàn bộ business logic của admin dashboard vào một service class riêng (code/services/admin.py).\nĐổi tên AdminStack → FrontendStack cho đúng với trách nhiệm; cập nhật toàn bộ tham chiếu. 26/11/2025 26/11/2025 5 Họp team để thiết kế chiến lược load dữ liệu từ S3 vào RDS mỗi khi RDS được khởi động.\nYêu cầu: tránh load toàn bộ dataset mỗi lần. Dữ liệu động (lịch hẹn, lịch làm việc) thay đổi thường xuyên → không thể reload tất cả.\nGiải pháp: giới hạn dữ liệu được load. Dữ liệu tĩnh (thông tin consultant) nên load toàn bộ. Dữ liệu động theo thời gian (lịch hẹn) chỉ nên load có điều kiện, ví dụ: trong khoảng thời gian liên quan đến thao tác của admin.\nCách làm hiện tại: load dữ liệu trong khoảng ±1 ngày so với ngày hiện tại.\nCập nhật vpc_stack để import S3 bucket được tạo thủ công bằng CLI.\nLệnh CLI:\naws s3 mb s3://meetassist-data-\u0026lt;account-id\u0026gt;-ap-southeast-1 --region ap-southeast-1\nDọn dẹp DashboardStack, loại bỏ các đoạn code Glue \u0026amp; analytics đã lỗi thời.\nCập nhật API cho customer và consultant; cải thiện logging cho Lambda AdminManager. 27/11/2025 27/11/2025 6 Quản lý rule EventBridge cho Lambda ArchiveData (bật/tắt/kiểm tra trạng thái/gọi thủ công).\nDisable: aws events disable-rule --name MeetAssist-ArchiveSchedule\nEnable: aws events enable-rule --name MeetAssist-ArchiveSchedule\nCheck status: aws events describe-rule --name MeetAssist-ArchiveSchedule\nInvoke: aws lambda invoke --function-name DashboardStack-ArchiveData --payload \u0026quot;{}\u0026quot; --cli-binary-format raw-in-base64-out NUL\nSửa lỗi CSV UTF-8 khi mở bằng Excel; index.py hiện hỗ trợ cả UTF-8 và UTF-8 BOM.\nTriển khai logic checksum cho ArchiveData để tránh upload lại CSV không đổi → giảm chi phí S3 PUT.\nPhương án 1: Không dùng checksum (luôn overwrite) – đơn giản nhưng timestamp “ồn ào” và chi phí cao hơn.\nPhương án 2 (khuyến nghị): Dùng checksum (MD5). Nếu không đổi → bỏ qua; nếu khác → upload.\nTạo archive_info.json trong S3 để:\n- Theo dõi trạng thái archiving\n- Lưu checksum\n- Ghi lại metrics, lỗi, thời gian cập nhật gần nhất\n- Có thể dùng về sau trong dashboard\nTriển khai cơ chế archiving RDS → S3 bằng Lambda chạy theo lịch:\n- Tạo ArchiveService để export CSV + upload lên S3 + ghi metadata\n- archive_handler chạy theo lịch (5 phút/lần, mặc định tắt)\n- Tự động bỏ qua các bảng không thay đổi dựa trên checksum\nCập nhật CDK để deploy Lambda + IAM + rule EventBridge.\nCải thiện xử lý lỗi cho các luồng consultant/appointment/program.\nCập nhật docstring của dashboard_handler để mô tả rõ ràng ranh giới giữa luồng CRUD và luồng archiving. 28/11/2025 28/11/2025 Thành tựu Tuần 12 Refactor toàn bộ backend \u0026amp; hạ tầng để tối ưu hơn và dễ bảo trì hơn. Nắm vững cách deploy và cấu hình VPC, RDS, S3, Lambda và EventBridge bằng CDK. Hoàn thành toàn bộ API cho dashboard và admin phục vụ analytics và nghiệp vụ quản lý. Tối ưu luồng import \u0026amp; archive dữ liệu giữa RDS ↔ S3. Xây dựng cơ chế checksum để giảm chi phí S3 và cải thiện hiệu quả xử lý dữ liệu. Tách biệt rõ ràng business logic vào các service class để dễ test và mở rộng. Cải thiện logging, debugging và cấu trúc tích hợp giữa API Gateway – Lambda. Hoàn tất quá trình migrate dữ liệu từ on-premise lên cloud và đảm bảo xử lý đúng trong các lần redeploy. "},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/5-workshop/5.12-cleanup/","title":"Dọn dẹp Tài nguyên","tags":[],"description":"","content":"Dọn dẹp Tài nguyên Sau khi hoàn thành workshop, dọn dẹp AWS resources để tránh phát sinh chi phí.\n⚠️ Cảnh báo: Các bước này sẽ XÓA VĨNH VIỄN tất cả data và resources!\nThứ tự Dọn dẹp Stop services trên EC2 Empty S3 buckets Terraform destroy Verify cleanup Bước 1: Stop Services trên EC2 Kết nối EC2 qua Session Manager:\nINSTANCE_ID=$(terraform -chdir=terraform output -raw ec2_instance_id) aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1 Stop Docker containers:\nsudo su - ec2-user cd /home/ec2-user/app # Stop containers docker-compose down # Remove volumes docker volume rm app_qdrant_storage Bước 2: Empty S3 Buckets S3 buckets phải empty trước khi Terraform destroy:\n# Lấy bucket name từ Terraform output BUCKET=$(terraform -chdir=terraform output -raw s3_bucket_name) # Empty bucket aws s3 rm s3://$BUCKET --recursive # Hoặc force delete aws s3 rb s3://$BUCKET --force Bước 3: Terraform Destroy cd terraform terraform plan -destroy terraform destroy Nhập yes khi được hỏi. Quá trình này mất khoảng 10-15 phút.\nBước 4: Manual Cleanup (nếu cần) Nếu còn resources chưa bị xóa:\n# CloudWatch Log Groups aws logs describe-log-groups --log-group-name-prefix /aws/arc | jq -r \u0026#39;.logGroups[].logGroupName\u0026#39; | xargs -I {} aws logs delete-log-group --log-group-name {} # EC2 Key Pair (nếu tạo manual) aws ec2 delete-key-pair --key-name arc-keypair # Amplify App (nếu tạo manual) aws amplify list-apps | jq -r \u0026#39;.apps[] | select(.name | contains(\u0026#34;arc\u0026#34;)) | .appId\u0026#39; | xargs -I {} aws amplify delete-app --app-id {} Bước 5: Verify Cleanup # Check EC2 aws ec2 describe-instances --filters \u0026#34;Name=tag:Name,Values=*arc*\u0026#34; --query \u0026#39;Reservations[].Instances[].InstanceId\u0026#39; # Check S3 aws s3 ls | grep arc # Check DynamoDB aws dynamodb list-tables --query \u0026#39;TableNames[?contains(@, `arc`)]\u0026#39; # Check Cognito aws cognito-idp list-user-pools --max-results 20 --query \u0026#39;UserPools[?contains(Name, `arc`)]\u0026#39; Tất cả commands trên không nên trả về kết quả.\nBước 6: Check Costs Mở AWS Billing Dashboard Kiểm tra Bills cho tháng hiện tại Set up Budgets alert cho tương lai Xử lý Lỗi Lỗi Giải pháp DependencyViolation Destroy theo thứ tự: terraform destroy -target=module.amplify trước BucketNotEmpty aws s3 rb s3://bucket-name --force DeleteConflict (IAM) Detach policies trước khi delete role Resource in use Đợi vài phút rồi retry Kết luận Chúc mừng bạn đã hoàn thành workshop Academic Research Chatbot (ARC)! 🎉\nNhững gì bạn đã học: Triển khai RAG chatbot trên AWS Sử dụng Amazon Bedrock (Claude 3.5 Sonnet + Cohere Embed) Xây dựng IDP pipeline với PyPDF2/Textract Vector search với Qdrant Authentication với Cognito Infrastructure as Code với Terraform Tài nguyên bổ sung: AWS Bedrock Documentation Qdrant Documentation FastAPI Documentation Checklist Stop Docker containers trên EC2 Empty S3 buckets Terraform destroy thành công Verify không còn resources Check billing Cảm ơn bạn đã tham gia workshop! 🙏\n"},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://khanguyense.github.io/fcj_khantse183212_Internship-Report/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]